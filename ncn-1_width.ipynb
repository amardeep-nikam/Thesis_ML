{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3212399a-6b38-4453-b9fb-89d1694041f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "45472a20-0887-4ef6-ab85-ad32790835bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Flow rate</th>\n",
       "      <th>Duty cycle</th>\n",
       "      <th>Pulse period</th>\n",
       "      <th>Laser energy</th>\n",
       "      <th>cavity width(mm)</th>\n",
       "      <th>cavity depth(µm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>68.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2108.0</td>\n",
       "      <td>67.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2233.0</td>\n",
       "      <td>61.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>52.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Voltage  Flow rate  Duty cycle  Pulse period  Laser energy  \\\n",
       "0       25       0.47          20            20             0   \n",
       "1       25       0.47          20            20             0   \n",
       "2       25       0.47          20            20             0   \n",
       "3       25       0.47          20            20             0   \n",
       "4       25       0.47          20            20             0   \n",
       "\n",
       "   cavity width(mm)  cavity depth(µm)  \n",
       "0            2285.0              72.1  \n",
       "1            2199.0              68.2  \n",
       "2            2108.0              67.2  \n",
       "3            2233.0              61.2  \n",
       "4            2046.0              52.2  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x1 input\n",
    "\n",
    "df = pd.read_csv('datasets/CNN_parameter_dataset.csv', encoding='utf-8')\n",
    "int_flow = df.copy()\n",
    "\n",
    "#preparing the dataset for spliting into features and labels \n",
    "int_flow.columns = [col.strip() for col in df.columns]\n",
    "int_flow.drop(['Sample','Cavity','Pulse width'], axis=1, inplace=True)\n",
    "int_flow.drop(['Pulse rms','Pulse pkpk'], axis=1, inplace=True)\n",
    "int_flow['cavity width(mm)'] = int_flow['cavity width(mm)']*1000\n",
    "#int_flow = sklearn.utils.shuffle(int_flow)\n",
    "int_flow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "37b9866d-7290-4e20-a4f7-276a23e51254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x2 input\n",
    "\n",
    "X2= []\n",
    "path = r'C:\\Users\\nikam\\Desktop\\Academics\\Thesis\\Internal_flow_experiments\\Internal_flow_current_data'   \n",
    "for folder in (os.listdir(path)):\n",
    "    dfs = []\n",
    "    \n",
    "    for file in (os.listdir(path + '\\\\'+folder)):\n",
    "        df = pd.read_csv(path + '\\\\'+folder + '\\\\'+file, encoding='unicode_escape', sep='\\t' )\n",
    "        dfs.append(df)\n",
    "    new_df = pd.concat(dfs)\n",
    "    for i in range(0,len(new_df),15):\n",
    "        _df = new_df[i:i+15].copy()\n",
    "        _df = _df.reset_index(drop=True)\n",
    "        idx = _df['Pulse rms [A]'].index[_df['Pulse rms [A]'].apply(np.isnan)]\n",
    "        \n",
    "        if len(idx)>0: \n",
    "            for ii in idx:\n",
    "                if ii == 0: \n",
    "                    replacing_val = _df['Pulse rms [A]'][ii+1]\n",
    "                elif ii == 14:\n",
    "                     replacing_val = _df['Pulse rms [A]'][ii-1]   \n",
    "                else:\n",
    "                    replacing_val = (_df['Pulse rms [A]'][ii-1]+_df['Pulse rms [A]'][ii+1])/2\n",
    "                _df.loc[ii,'Pulse rms [A]'] = replacing_val\n",
    "        X2.append(_df.iloc[:,-2:].to_numpy())        \n",
    "        \n",
    "X2 = np.asarray(X2, dtype=np.float16)\n",
    "X2 =np.expand_dims(X2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8e45932-ebb8-4424-ad03-fd5853050573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing X(features) and y(labels)\n",
    "X1 = int_flow.drop(['cavity width(mm)','cavity depth(µm)'], axis=1).to_numpy()\n",
    "#X1 =np.expand_dims(X1,axis=1)\n",
    "y = int_flow[['cavity width(mm)']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e99af64b-9bab-4fc5-b0aa-a6a4f83e2b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X1_train, X1_test,X2_train, X2_test, y_train, y_test = model_selection.train_test_split(X1, X2, y, test_size=0.2, random_state=1)\n",
    "X1_train_1, X1_dev, X2_train_1, X2_dev, y_train_1, y_dev = model_selection.train_test_split(X1_train, X2_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5658fdc4-2264-47c5-aa50-2c2fbb123e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nncnn(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(5, 10)        \n",
    "        self.cnn1 = nn.Conv2d(1, 5, (2,2))\n",
    "        \n",
    "        self.fc2 = nn.Linear(80, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "        self.fc4 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x1,x2):\n",
    "        x1 = F.relu(self.fc1(x1))\n",
    "        \n",
    "        x2 = self.cnn1(x2).view(x1.size(0),-1)\n",
    "        #print(x1.shape, x2.shape)\n",
    "        x_joined = torch.cat([x1,x2], dim=1)\n",
    "        #print(x1.shape, x2.shape, x_joined.shape)\n",
    "        x_joined = F.relu(self.fc2(x_joined))\n",
    "        x_joined = F.relu(self.fc3(x_joined))\n",
    "        x_joined = self.fc4(x_joined)\n",
    "\n",
    "        return x_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36549066-84ab-4342-9039-a60c2547d50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nncnn(\n",
       "  (fc1): Linear(in_features=5, out_features=10, bias=True)\n",
       "  (cnn1): Conv2d(1, 5, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (fc2): Linear(in_features=80, out_features=50, bias=True)\n",
       "  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (fc4): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nncnn()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "74ce8085-14e2-4b7e-9a1e-bfdf251ec665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the neuralnetwork model\n",
    "\n",
    "X1_train_1 = torch.tensor(X1_train_1, dtype=torch.float64)\n",
    "X2_train_1 = torch.tensor(X2_train_1, dtype=torch.float64)\n",
    "y_train_1 = torch.tensor(y_train_1)\n",
    "\n",
    "X1_dev = torch.tensor(X1_dev, dtype=torch.float64)\n",
    "X2_dev = torch.tensor(X2_dev, dtype=torch.float64)\n",
    "y_dev = torch.tensor(y_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fb33d217-a28c-41cc-889e-ec2722e8481c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                             | 46/10000 [00:00<00:22, 450.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 5106172.000000).  Saving model ...\n",
      "Validation loss decreased (5106172.000000 --> 4800970.000000).  Saving model ...\n",
      "Validation loss decreased (4800970.000000 --> 3159737.750000).  Saving model ...\n",
      "Validation loss decreased (3159737.750000 --> 135839.406250).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "Validation loss decreased (135839.406250 --> 135486.000000).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "Validation loss decreased (135486.000000 --> 130697.210938).  Saving model ...\n",
      "Validation loss decreased (130697.210938 --> 127709.789062).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (127709.789062 --> 126229.453125).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▏                                                                           | 154/10000 [00:00<00:19, 506.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (126229.453125 --> 123512.445312).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (123512.445312 --> 123432.289062).  Saving model ...\n",
      "Validation loss decreased (123432.289062 --> 121822.992188).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (121822.992188 --> 121159.890625).  Saving model ...\n",
      "Validation loss decreased (121159.890625 --> 119998.023438).  Saving model ...\n",
      "Validation loss decreased (119998.023438 --> 119751.054688).  Saving model ...\n",
      "Validation loss decreased (119751.054688 --> 118429.242188).  Saving model ...\n",
      "Validation loss decreased (118429.242188 --> 117410.679688).  Saving model ...\n",
      "Validation loss decreased (117410.679688 --> 116666.820312).  Saving model ...\n",
      "Validation loss decreased (116666.820312 --> 115455.476562).  Saving model ...\n",
      "Validation loss decreased (115455.476562 --> 114556.656250).  Saving model ...\n",
      "Validation loss decreased (114556.656250 --> 113662.328125).  Saving model ...\n",
      "Validation loss decreased (113662.328125 --> 112643.781250).  Saving model ...\n",
      "Validation loss decreased (112643.781250 --> 111819.640625).  Saving model ...\n",
      "Validation loss decreased (111819.640625 --> 110920.914062).  Saving model ...\n",
      "Validation loss decreased (110920.914062 --> 110044.375000).  Saving model ...\n",
      "Validation loss decreased (110044.375000 --> 109230.937500).  Saving model ...\n",
      "Validation loss decreased (109230.937500 --> 108370.187500).  Saving model ...\n",
      "Validation loss decreased (108370.187500 --> 107560.257812).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██                                                                           | 260/10000 [00:00<00:18, 514.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (107560.257812 --> 106749.960938).  Saving model ...\n",
      "Validation loss decreased (106749.960938 --> 105944.242188).  Saving model ...\n",
      "Validation loss decreased (105944.242188 --> 105170.218750).  Saving model ...\n",
      "Validation loss decreased (105170.218750 --> 104395.796875).  Saving model ...\n",
      "Validation loss decreased (104395.796875 --> 103851.257812).  Saving model ...\n",
      "Validation loss decreased (103851.257812 --> 103325.210938).  Saving model ...\n",
      "Validation loss decreased (103325.210938 --> 102772.164062).  Saving model ...\n",
      "Validation loss decreased (102772.164062 --> 102235.398438).  Saving model ...\n",
      "Validation loss decreased (102235.398438 --> 101690.000000).  Saving model ...\n",
      "Validation loss decreased (101690.000000 --> 101184.484375).  Saving model ...\n",
      "Validation loss decreased (101184.484375 --> 100693.750000).  Saving model ...\n",
      "Validation loss decreased (100693.750000 --> 100234.125000).  Saving model ...\n",
      "Validation loss decreased (100234.125000 --> 99800.796875).  Saving model ...\n",
      "Validation loss decreased (99800.796875 --> 99389.062500).  Saving model ...\n",
      "Validation loss decreased (99389.062500 --> 99005.101562).  Saving model ...\n",
      "Validation loss decreased (99005.101562 --> 98641.062500).  Saving model ...\n",
      "Validation loss decreased (98641.062500 --> 98303.539062).  Saving model ...\n",
      "Validation loss decreased (98303.539062 --> 97988.203125).  Saving model ...\n",
      "Validation loss decreased (97988.203125 --> 97698.054688).  Saving model ...\n",
      "Validation loss decreased (97698.054688 --> 97431.867188).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▊                                                                          | 363/10000 [00:00<00:19, 500.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (97431.867188 --> 97189.312500).  Saving model ...\n",
      "Validation loss decreased (97189.312500 --> 96970.210938).  Saving model ...\n",
      "Validation loss decreased (96970.210938 --> 96773.085938).  Saving model ...\n",
      "Validation loss decreased (96773.085938 --> 96598.062500).  Saving model ...\n",
      "Validation loss decreased (96598.062500 --> 96443.468750).  Saving model ...\n",
      "Validation loss decreased (96443.468750 --> 96309.382812).  Saving model ...\n",
      "Validation loss decreased (96309.382812 --> 96194.757812).  Saving model ...\n",
      "Validation loss decreased (96194.757812 --> 96099.335938).  Saving model ...\n",
      "Validation loss decreased (96099.335938 --> 96022.257812).  Saving model ...\n",
      "Validation loss decreased (96022.257812 --> 95874.843750).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (95874.843750 --> 95721.093750).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "Validation loss decreased (95721.093750 --> 95228.429688).  Saving model ...\n",
      "Validation loss decreased (95228.429688 --> 95116.835938).  Saving model ...\n",
      "Validation loss decreased (95116.835938 --> 95005.625000).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▌                                                                         | 464/10000 [00:00<00:19, 480.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (95005.625000 --> 94967.468750).  Saving model ...\n",
      "Validation loss decreased (94967.468750 --> 94674.726562).  Saving model ...\n",
      "Validation loss decreased (94674.726562 --> 94643.054688).  Saving model ...\n",
      "Validation loss decreased (94643.054688 --> 94419.054688).  Saving model ...\n",
      "Validation loss decreased (94419.054688 --> 94306.976562).  Saving model ...\n",
      "Validation loss decreased (94306.976562 --> 94179.421875).  Saving model ...\n",
      "Validation loss decreased (94179.421875 --> 94081.335938).  Saving model ...\n",
      "Validation loss decreased (94081.335938 --> 94046.992188).  Saving model ...\n",
      "Validation loss decreased (94046.992188 --> 93900.257812).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (93900.257812 --> 93806.859375).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (93806.859375 --> 93738.460938).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▎                                                                        | 560/10000 [00:01<00:20, 460.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "EarlyStopping counter: 9 out of 50\n",
      "EarlyStopping counter: 10 out of 50\n",
      "EarlyStopping counter: 11 out of 50\n",
      "EarlyStopping counter: 12 out of 50\n",
      "EarlyStopping counter: 13 out of 50\n",
      "EarlyStopping counter: 14 out of 50\n",
      "EarlyStopping counter: 15 out of 50\n",
      "EarlyStopping counter: 16 out of 50\n",
      "EarlyStopping counter: 17 out of 50\n",
      "EarlyStopping counter: 18 out of 50\n",
      "EarlyStopping counter: 19 out of 50\n",
      "EarlyStopping counter: 20 out of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▋                                                                        | 613/10000 [00:01<00:19, 477.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 21 out of 50\n",
      "EarlyStopping counter: 22 out of 50\n",
      "EarlyStopping counter: 23 out of 50\n",
      "EarlyStopping counter: 24 out of 50\n",
      "EarlyStopping counter: 25 out of 50\n",
      "EarlyStopping counter: 26 out of 50\n",
      "EarlyStopping counter: 27 out of 50\n",
      "EarlyStopping counter: 28 out of 50\n",
      "EarlyStopping counter: 29 out of 50\n",
      "EarlyStopping counter: 30 out of 50\n",
      "EarlyStopping counter: 31 out of 50\n",
      "EarlyStopping counter: 32 out of 50\n",
      "EarlyStopping counter: 33 out of 50\n",
      "EarlyStopping counter: 34 out of 50\n",
      "EarlyStopping counter: 35 out of 50\n",
      "EarlyStopping counter: 36 out of 50\n",
      "EarlyStopping counter: 37 out of 50\n",
      "EarlyStopping counter: 38 out of 50\n",
      "EarlyStopping counter: 39 out of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▍                                                                       | 705/10000 [00:01<00:19, 479.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 40 out of 50\n",
      "EarlyStopping counter: 41 out of 50\n",
      "EarlyStopping counter: 42 out of 50\n",
      "EarlyStopping counter: 43 out of 50\n",
      "EarlyStopping counter: 44 out of 50\n",
      "EarlyStopping counter: 45 out of 50\n",
      "EarlyStopping counter: 46 out of 50\n",
      "EarlyStopping counter: 47 out of 50\n",
      "EarlyStopping counter: 48 out of 50\n",
      "EarlyStopping counter: 49 out of 50\n",
      "EarlyStopping counter: 50 out of 50\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "net = nncnn()\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.02)\n",
    "\n",
    "# to track the training loss as the model trains\n",
    "t_l = []\n",
    "# to track the validation loss as the model trains\n",
    "d_l = []\n",
    "\n",
    "#initialize the early_stopping object\n",
    "early_stopping = EarlyStopping(patience=50, verbose=True)\n",
    "\n",
    "for epoch in tqdm(range(10000)):# 10000 full passes over the data        \n",
    "    net.zero_grad() # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "    output = net(X1_train_1.float(), X2_train_1.float()) # pass in the training batch \n",
    "    loss = loss_function(output, y_train_1.float()) # calc and grab the loss value\n",
    "    loss.backward() # apply this loss backwards thru the network's parameters\n",
    "    optimizer.step() # attempt to optimize weights to account for loss/gradients\n",
    "    if epoch%5 == 0: \n",
    "        with torch.no_grad():\n",
    "            y_predict = net(X1_dev.float(), X2_dev.float())\n",
    "            dev_error = loss_function(y_predict, y_dev.float())\n",
    "            #print(f'train_loss..:{loss.item()} dev_loss..:{dev_error.item()} ')\n",
    "            t_l.append(loss.item())\n",
    "            d_l.append(dev_error.item())\n",
    "            # early_stopping needs the validation loss to check if it has decresed, \n",
    "            # and if it has, it will make a checkpoint of the current model\n",
    "            early_stopping(dev_error, net)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break  \n",
    "            #print(loss) # print loss. We hope loss (train_loss..:{loss.item()} a measure of wrong-ness) declines!\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0ff20ffc-f2f7-4498-a681-5b9359d3d58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# evenly sampled time at 200ms intervals\n",
    "#t = np.arange(0., 5., 0.2)\n",
    "\n",
    "# red dashes, blue squares and green triangles\n",
    "plt.plot(t_l,'r--', d_l,'b--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8fd16a48-a4fe-4c60-b0c8-c45a065bafd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101228.4140625\n",
      "(tensor([991.], dtype=torch.float64), tensor([1318.5577], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2658.], dtype=torch.float64), tensor([2359.4265], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2880.], dtype=torch.float64), tensor([2892.9070], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2424.], dtype=torch.float64), tensor([2503.8391], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1772.], dtype=torch.float64), tensor([1604.2592], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2538.], dtype=torch.float64), tensor([2573.2671], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2677.], dtype=torch.float64), tensor([2874.6394], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2785.], dtype=torch.float64), tensor([2640.1541], grad_fn=<UnbindBackward0>))\n",
      "(tensor([3021.], dtype=torch.float64), tensor([2256.9751], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1823.], dtype=torch.float64), tensor([1998.3326], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1738.], dtype=torch.float64), tensor([1844.7240], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1920.], dtype=torch.float64), tensor([2271.4436], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2430.], dtype=torch.float64), tensor([2297.2673], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2411.], dtype=torch.float64), tensor([2248.6345], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1515.], dtype=torch.float64), tensor([1605.2914], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2078.], dtype=torch.float64), tensor([2173.3096], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1988.], dtype=torch.float64), tensor([2860.5618], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2411.], dtype=torch.float64), tensor([2347.0635], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2222.], dtype=torch.float64), tensor([2346.8718], grad_fn=<UnbindBackward0>))\n",
      "(tensor([831.], dtype=torch.float64), tensor([1205.8661], grad_fn=<UnbindBackward0>))\n",
      "0.6962624683885923\n",
      "MAPE for width:  0.12541864709474787\n",
      "MSE for width:  101228.40756435246\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "X1_test = torch.tensor(X1_test)\n",
    "X2_test = torch.tensor(X2_test)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "y_predict_1 = net(X1_test.float(), X2_test.float())\n",
    "error = loss_function(y_predict_1, y_test.float())\n",
    "\n",
    "print(error.item())\n",
    "for a in (list(zip(y_test,y_predict_1))):\n",
    "    print(a)\n",
    "    \n",
    "print(r2_score(y_test.detach().numpy()[:,0], y_predict_1.detach().numpy()[:,0]))\n",
    "#print(r2_score(y_test.detach().numpy()[:,1], y_predict_1.detach().numpy()[:,1]))\n",
    "\n",
    "print('MAPE for width: ', mean_absolute_percentage_error(y_test.detach().numpy()[:,0], y_predict_1.detach().numpy()[:,0]))\n",
    "#print('MAPE for depth: ', mean_absolute_percentage_error(y_test.detach().numpy()[:,1], y_predict_1.detach().numpy()[:,1]))\n",
    "\n",
    "print('MSE for width: ', mean_squared_error(y_test.detach().numpy()[:,0], y_predict_1.detach().numpy()[:,0]))\n",
    "#print('MSE for depth: ', mean_squared_error(y_test.detach().numpy()[:,1], y_predict_1.detach().numpy()[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "312ddda9-4c02-477a-84f4-629e32fa4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "\t\"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "\tdef __init__(self, patience, verbose=False, delta=0, save_path='checkpoint.pt'):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\t\tpatience (int): How long to wait after last time validation loss improved.\n",
    "\t\t\t\t\t\t\tDefault: 7\n",
    "\t\t\tverbose (bool): If True, prints a message for each validation loss improvement.\n",
    "\t\t\t\t\t\t\tDefault: False\n",
    "\t\t\tdelta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "\t\t\t\t\t\t\tDefault: 0\n",
    "\t\t\"\"\"\n",
    "\t\tself.patience = patience\n",
    "\t\tself.verbose = verbose\n",
    "\t\tself.counter = 0\n",
    "\t\tself.best_score = None\n",
    "\t\tself.early_stop = False\n",
    "\t\tself.val_loss_min = np.inf\n",
    "\t\tself.delta = delta\n",
    "\t\tself.save_path = save_path\n",
    "\t\tos.makedirs(pathlib.Path(self.save_path).parent, exist_ok=True)\n",
    "\n",
    "\tdef __call__(self, val_loss, model):\n",
    "\n",
    "\t\tscore = -val_loss\n",
    "\n",
    "\t\tif self.best_score is None:\n",
    "\t\t\tself.best_score = score\n",
    "\t\t\tself.save_checkpoint(val_loss, model)\n",
    "\t\telif score < self.best_score - self.delta:\n",
    "\t\t\tself.counter += 1\n",
    "\t\t\tprint(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "\t\t\tif self.counter >= self.patience:\n",
    "\t\t\t\tself.early_stop = True\n",
    "\t\telse:\n",
    "\t\t\tself.best_score = score\n",
    "\t\t\tself.save_checkpoint(val_loss, model)\n",
    "\t\t\tself.counter = 0\n",
    "\n",
    "\tdef save_checkpoint(self, val_loss, model):\n",
    "\t\t\"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "\t\tif self.verbose:\n",
    "\t\t\tprint(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "\t\ttorch.save(model.state_dict(), self.save_path)\n",
    "\t\tself.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc3632-32e4-4107-b749-e319a6664ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
