{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8310e7a7-4ce1-423f-baec-9baf6cbefbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a0577d5b-20b2-4ef7-a4ff-516a2b55b535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Cavity</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Flow rate</th>\n",
       "      <th>Duty cycle</th>\n",
       "      <th>Pulse width</th>\n",
       "      <th>Pulse period</th>\n",
       "      <th>Pulse pkpk</th>\n",
       "      <th>Pulse rms</th>\n",
       "      <th>Laser energy</th>\n",
       "      <th>cavity width(mm)</th>\n",
       "      <th>cavity depth(µm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>3.132333</td>\n",
       "      <td>1.318667</td>\n",
       "      <td>0</td>\n",
       "      <td>2.285</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>3.010667</td>\n",
       "      <td>1.273267</td>\n",
       "      <td>0</td>\n",
       "      <td>2.199</td>\n",
       "      <td>68.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>3.329467</td>\n",
       "      <td>1.397467</td>\n",
       "      <td>0</td>\n",
       "      <td>2.108</td>\n",
       "      <td>67.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>3.260867</td>\n",
       "      <td>1.379214</td>\n",
       "      <td>0</td>\n",
       "      <td>2.233</td>\n",
       "      <td>61.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>3.198667</td>\n",
       "      <td>1.348800</td>\n",
       "      <td>0</td>\n",
       "      <td>2.046</td>\n",
       "      <td>52.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample  Cavity  Voltage  Flow rate  Duty cycle  Pulse width  Pulse period  \\\n",
       "0        5      6       25       0.47          20            4            20   \n",
       "1        5      7       25       0.47          20            4            20   \n",
       "2        5      8       25       0.47          20            4            20   \n",
       "3        5      9       25       0.47          20            4            20   \n",
       "4        5     10       25       0.47          20            4            20   \n",
       "\n",
       "   Pulse pkpk  Pulse rms  Laser energy  cavity width(mm)  cavity depth(µm)  \n",
       "0    3.132333   1.318667             0             2.285              72.1  \n",
       "1    3.010667   1.273267             0             2.199              68.2  \n",
       "2    3.329467   1.397467             0             2.108              67.2  \n",
       "3    3.260867   1.379214             0             2.233              61.2  \n",
       "4    3.198667   1.348800             0             2.046              52.2  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/CNN_parameter_dataset.csv')\n",
    "int_flow = df.copy()\n",
    "int_flow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a987164d-9ef9-4b5e-a30c-fa9416369b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Flow rate</th>\n",
       "      <th>Duty cycle</th>\n",
       "      <th>Pulse period</th>\n",
       "      <th>Pulse pkpk</th>\n",
       "      <th>Pulse rms</th>\n",
       "      <th>Laser energy</th>\n",
       "      <th>cavity width(mm)</th>\n",
       "      <th>cavity depth(µm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3.132333</td>\n",
       "      <td>1.318667</td>\n",
       "      <td>0</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3.010667</td>\n",
       "      <td>1.273267</td>\n",
       "      <td>0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>68.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3.329467</td>\n",
       "      <td>1.397467</td>\n",
       "      <td>0</td>\n",
       "      <td>2108.0</td>\n",
       "      <td>67.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3.260867</td>\n",
       "      <td>1.379214</td>\n",
       "      <td>0</td>\n",
       "      <td>2233.0</td>\n",
       "      <td>61.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3.198667</td>\n",
       "      <td>1.348800</td>\n",
       "      <td>0</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>52.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Voltage  Flow rate  Duty cycle  Pulse period  Pulse pkpk  Pulse rms  \\\n",
       "0       25       0.47          20            20    3.132333   1.318667   \n",
       "1       25       0.47          20            20    3.010667   1.273267   \n",
       "2       25       0.47          20            20    3.329467   1.397467   \n",
       "3       25       0.47          20            20    3.260867   1.379214   \n",
       "4       25       0.47          20            20    3.198667   1.348800   \n",
       "\n",
       "   Laser energy  cavity width(mm)  cavity depth(µm)  \n",
       "0             0            2285.0              72.1  \n",
       "1             0            2199.0              68.2  \n",
       "2             0            2108.0              67.2  \n",
       "3             0            2233.0              61.2  \n",
       "4             0            2046.0              52.2  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparing the dataset for spliting into features and labels \n",
    "int_flow.columns = [col.strip() for col in df.columns]\n",
    "int_flow.drop(['Sample','Cavity','Pulse width'], axis=1, inplace=True)\n",
    "int_flow['cavity width(mm)'] = int_flow['cavity width(mm)']*1000\n",
    "#int_flow = sklearn.utils.shuffle(int_flow)\n",
    "int_flow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8c316f1a-29a8-44b1-b001-43da0cce9502",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = int_flow.drop(['cavity width(mm)', 'cavity depth(µm)'], axis=1).values\n",
    "#X = preprocessing.scale(X)\n",
    "y = int_flow[['cavity width(mm)']].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e16a7245-8cce-4d08-bd16-eaa255fe40e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_dev, y_train_1, y_dev = model_selection.train_test_split(X_train, y_train, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a5a2f72f-624c-43bc-a923-3679ccec9d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a neural network model\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(7, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b92917c2-8477-4236-880c-5dc75dba1855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([62, 7]), torch.Size([62, 1]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the neuralnetwork model\n",
    "X_train_1 = torch.tensor(X_train_1)\n",
    "y_train_1 = torch.tensor(y_train_1)\n",
    "\n",
    "X_dev = torch.tensor(X_dev)\n",
    "y_dev = torch.tensor(y_dev)\n",
    "\n",
    "X_train_1.shape, y_train_1.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "62cb7e93-6913-4cd6-ae34-93546406e2e5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                           | 180/10000 [00:00<00:10, 904.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 4878061.000000).  Saving model ...\n",
      "Validation loss decreased (4878061.000000 --> 4860587.000000).  Saving model ...\n",
      "Validation loss decreased (4860587.000000 --> 4811967.000000).  Saving model ...\n",
      "Validation loss decreased (4811967.000000 --> 4688197.000000).  Saving model ...\n",
      "Validation loss decreased (4688197.000000 --> 4417101.000000).  Saving model ...\n",
      "Validation loss decreased (4417101.000000 --> 3918946.000000).  Saving model ...\n",
      "Validation loss decreased (3918946.000000 --> 3133563.250000).  Saving model ...\n",
      "Validation loss decreased (3133563.250000 --> 2093260.875000).  Saving model ...\n",
      "Validation loss decreased (2093260.875000 --> 1049123.875000).  Saving model ...\n",
      "Validation loss decreased (1049123.875000 --> 538236.000000).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 100\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Validation loss decreased (538236.000000 --> 434028.812500).  Saving model ...\n",
      "Validation loss decreased (434028.812500 --> 392429.187500).  Saving model ...\n",
      "Validation loss decreased (392429.187500 --> 386518.500000).  Saving model ...\n",
      "Validation loss decreased (386518.500000 --> 347368.375000).  Saving model ...\n",
      "Validation loss decreased (347368.375000 --> 321260.031250).  Saving model ...\n",
      "Validation loss decreased (321260.031250 --> 318313.656250).  Saving model ...\n",
      "Validation loss decreased (318313.656250 --> 308128.187500).  Saving model ...\n",
      "Validation loss decreased (308128.187500 --> 293768.031250).  Saving model ...\n",
      "Validation loss decreased (293768.031250 --> 286576.125000).  Saving model ...\n",
      "Validation loss decreased (286576.125000 --> 282204.281250).  Saving model ...\n",
      "Validation loss decreased (282204.281250 --> 278580.687500).  Saving model ...\n",
      "Validation loss decreased (278580.687500 --> 276581.031250).  Saving model ...\n",
      "Validation loss decreased (276581.031250 --> 274509.781250).  Saving model ...\n",
      "Validation loss decreased (274509.781250 --> 271811.031250).  Saving model ...\n",
      "Validation loss decreased (271811.031250 --> 269490.531250).  Saving model ...\n",
      "Validation loss decreased (269490.531250 --> 267713.718750).  Saving model ...\n",
      "Validation loss decreased (267713.718750 --> 266245.937500).  Saving model ...\n",
      "Validation loss decreased (266245.937500 --> 264876.500000).  Saving model ...\n",
      "Validation loss decreased (264876.500000 --> 263346.312500).  Saving model ...\n",
      "Validation loss decreased (263346.312500 --> 261648.890625).  Saving model ...\n",
      "Validation loss decreased (261648.890625 --> 259938.968750).  Saving model ...\n",
      "Validation loss decreased (259938.968750 --> 258274.171875).  Saving model ...\n",
      "Validation loss decreased (258274.171875 --> 256617.015625).  Saving model ...\n",
      "Validation loss decreased (256617.015625 --> 254902.703125).  Saving model ...\n",
      "Validation loss decreased (254902.703125 --> 253105.281250).  Saving model ...\n",
      "Validation loss decreased (253105.281250 --> 251258.156250).  Saving model ...\n",
      "Validation loss decreased (251258.156250 --> 249399.859375).  Saving model ...\n",
      "Validation loss decreased (249399.859375 --> 247538.703125).  Saving model ...\n",
      "Validation loss decreased (247538.703125 --> 245661.203125).  Saving model ...\n",
      "Validation loss decreased (245661.203125 --> 243757.296875).  Saving model ...\n",
      "Validation loss decreased (243757.296875 --> 241832.015625).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▊                                                                          | 371/10000 [00:00<00:10, 910.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (241832.015625 --> 239896.250000).  Saving model ...\n",
      "Validation loss decreased (239896.250000 --> 237953.421875).  Saving model ...\n",
      "Validation loss decreased (237953.421875 --> 235999.109375).  Saving model ...\n",
      "Validation loss decreased (235999.109375 --> 234028.421875).  Saving model ...\n",
      "Validation loss decreased (234028.421875 --> 232040.906250).  Saving model ...\n",
      "Validation loss decreased (232040.906250 --> 230038.140625).  Saving model ...\n",
      "Validation loss decreased (230038.140625 --> 228020.500000).  Saving model ...\n",
      "Validation loss decreased (228020.500000 --> 225985.765625).  Saving model ...\n",
      "Validation loss decreased (225985.765625 --> 223932.468750).  Saving model ...\n",
      "Validation loss decreased (223932.468750 --> 221860.187500).  Saving model ...\n",
      "Validation loss decreased (221860.187500 --> 219769.468750).  Saving model ...\n",
      "Validation loss decreased (219769.468750 --> 217660.390625).  Saving model ...\n",
      "Validation loss decreased (217660.390625 --> 215532.625000).  Saving model ...\n",
      "Validation loss decreased (215532.625000 --> 213385.875000).  Saving model ...\n",
      "Validation loss decreased (213385.875000 --> 211220.890625).  Saving model ...\n",
      "Validation loss decreased (211220.890625 --> 209038.046875).  Saving model ...\n",
      "Validation loss decreased (209038.046875 --> 206837.812500).  Saving model ...\n",
      "Validation loss decreased (206837.812500 --> 204620.828125).  Saving model ...\n",
      "Validation loss decreased (204620.828125 --> 202387.828125).  Saving model ...\n",
      "Validation loss decreased (202387.828125 --> 200139.890625).  Saving model ...\n",
      "Validation loss decreased (200139.890625 --> 197878.203125).  Saving model ...\n",
      "Validation loss decreased (197878.203125 --> 195604.296875).  Saving model ...\n",
      "Validation loss decreased (195604.296875 --> 193319.828125).  Saving model ...\n",
      "Validation loss decreased (193319.828125 --> 191026.750000).  Saving model ...\n",
      "Validation loss decreased (191026.750000 --> 188727.312500).  Saving model ...\n",
      "Validation loss decreased (188727.312500 --> 186424.453125).  Saving model ...\n",
      "Validation loss decreased (186424.453125 --> 184120.906250).  Saving model ...\n",
      "Validation loss decreased (184120.906250 --> 181819.937500).  Saving model ...\n",
      "Validation loss decreased (181819.937500 --> 179525.484375).  Saving model ...\n",
      "Validation loss decreased (179525.484375 --> 177241.250000).  Saving model ...\n",
      "Validation loss decreased (177241.250000 --> 174971.812500).  Saving model ...\n",
      "Validation loss decreased (174971.812500 --> 172721.750000).  Saving model ...\n",
      "Validation loss decreased (172721.750000 --> 170495.968750).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▋                                                                        | 491/10000 [00:00<00:09, 1012.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (170495.968750 --> 168299.796875).  Saving model ...\n",
      "Validation loss decreased (168299.796875 --> 166138.703125).  Saving model ...\n",
      "Validation loss decreased (166138.703125 --> 164018.156250).  Saving model ...\n",
      "Validation loss decreased (164018.156250 --> 161944.000000).  Saving model ...\n",
      "Validation loss decreased (161944.000000 --> 159921.812500).  Saving model ...\n",
      "Validation loss decreased (159921.812500 --> 157957.171875).  Saving model ...\n",
      "Validation loss decreased (157957.171875 --> 156055.515625).  Saving model ...\n",
      "Validation loss decreased (156055.515625 --> 154222.031250).  Saving model ...\n",
      "Validation loss decreased (154222.031250 --> 152461.390625).  Saving model ...\n",
      "Validation loss decreased (152461.390625 --> 150777.859375).  Saving model ...\n",
      "Validation loss decreased (150777.859375 --> 149175.140625).  Saving model ...\n",
      "Validation loss decreased (149175.140625 --> 147656.015625).  Saving model ...\n",
      "Validation loss decreased (147656.015625 --> 146222.796875).  Saving model ...\n",
      "Validation loss decreased (146222.796875 --> 144876.812500).  Saving model ...\n",
      "Validation loss decreased (144876.812500 --> 143618.703125).  Saving model ...\n",
      "Validation loss decreased (143618.703125 --> 142806.796875).  Saving model ...\n",
      "Validation loss decreased (142806.796875 --> 142065.515625).  Saving model ...\n",
      "Validation loss decreased (142065.515625 --> 141334.000000).  Saving model ...\n",
      "Validation loss decreased (141334.000000 --> 140424.078125).  Saving model ...\n",
      "Validation loss decreased (140424.078125 --> 139354.328125).  Saving model ...\n",
      "Validation loss decreased (139354.328125 --> 138322.031250).  Saving model ...\n",
      "Validation loss decreased (138322.031250 --> 137473.718750).  Saving model ...\n",
      "Validation loss decreased (137473.718750 --> 136792.328125).  Saving model ...\n",
      "Validation loss decreased (136792.328125 --> 136202.312500).  Saving model ...\n",
      "Validation loss decreased (136202.312500 --> 135710.343750).  Saving model ...\n",
      "Validation loss decreased (135710.343750 --> 135206.046875).  Saving model ...\n",
      "Validation loss decreased (135206.046875 --> 134717.468750).  Saving model ...\n",
      "Validation loss decreased (134717.468750 --> 134285.203125).  Saving model ...\n",
      "Validation loss decreased (134285.203125 --> 133920.140625).  Saving model ...\n",
      "Validation loss decreased (133920.140625 --> 133582.140625).  Saving model ...\n",
      "Validation loss decreased (133582.140625 --> 133101.796875).  Saving model ...\n",
      "Validation loss decreased (133101.796875 --> 132844.781250).  Saving model ...\n",
      "Validation loss decreased (132844.781250 --> 132791.171875).  Saving model ...\n",
      "Validation loss decreased (132791.171875 --> 132563.812500).  Saving model ...\n",
      "Validation loss decreased (132563.812500 --> 132238.500000).  Saving model ...\n",
      "Validation loss decreased (132238.500000 --> 131965.453125).  Saving model ...\n",
      "Validation loss decreased (131965.453125 --> 131848.234375).  Saving model ...\n",
      "Validation loss decreased (131848.234375 --> 131745.031250).  Saving model ...\n",
      "Validation loss decreased (131745.031250 --> 131525.406250).  Saving model ...\n",
      "Validation loss decreased (131525.406250 --> 131275.093750).  Saving model ...\n",
      "Validation loss decreased (131275.093750 --> 131209.156250).  Saving model ...\n",
      "Validation loss decreased (131209.156250 --> 131152.234375).  Saving model ...\n",
      "Validation loss decreased (131152.234375 --> 130982.320312).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▎                                                                       | 696/10000 [00:00<00:09, 959.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (130982.320312 --> 130846.703125).  Saving model ...\n",
      "Validation loss decreased (130846.703125 --> 130810.296875).  Saving model ...\n",
      "Validation loss decreased (130810.296875 --> 130790.335938).  Saving model ...\n",
      "Validation loss decreased (130790.335938 --> 130670.390625).  Saving model ...\n",
      "Validation loss decreased (130670.390625 --> 130603.375000).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 100\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Validation loss decreased (130603.375000 --> 130586.312500).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 100\n",
      "EarlyStopping counter: 2 out of 100\n",
      "EarlyStopping counter: 3 out of 100\n",
      "EarlyStopping counter: 4 out of 100\n",
      "EarlyStopping counter: 5 out of 100\n",
      "EarlyStopping counter: 6 out of 100\n",
      "EarlyStopping counter: 7 out of 100\n",
      "EarlyStopping counter: 8 out of 100\n",
      "EarlyStopping counter: 9 out of 100\n",
      "EarlyStopping counter: 10 out of 100\n",
      "EarlyStopping counter: 11 out of 100\n",
      "EarlyStopping counter: 12 out of 100\n",
      "EarlyStopping counter: 13 out of 100\n",
      "EarlyStopping counter: 14 out of 100\n",
      "EarlyStopping counter: 15 out of 100\n",
      "EarlyStopping counter: 16 out of 100\n",
      "EarlyStopping counter: 17 out of 100\n",
      "EarlyStopping counter: 18 out of 100\n",
      "EarlyStopping counter: 19 out of 100\n",
      "EarlyStopping counter: 20 out of 100\n",
      "EarlyStopping counter: 21 out of 100\n",
      "EarlyStopping counter: 22 out of 100\n",
      "EarlyStopping counter: 23 out of 100\n",
      "EarlyStopping counter: 24 out of 100\n",
      "EarlyStopping counter: 25 out of 100\n",
      "EarlyStopping counter: 26 out of 100\n",
      "EarlyStopping counter: 27 out of 100\n",
      "EarlyStopping counter: 28 out of 100\n",
      "EarlyStopping counter: 29 out of 100\n",
      "EarlyStopping counter: 30 out of 100\n",
      "EarlyStopping counter: 31 out of 100\n",
      "EarlyStopping counter: 32 out of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▎                                                                    | 968/10000 [00:00<00:07, 1165.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 33 out of 100\n",
      "EarlyStopping counter: 34 out of 100\n",
      "EarlyStopping counter: 35 out of 100\n",
      "EarlyStopping counter: 36 out of 100\n",
      "EarlyStopping counter: 37 out of 100\n",
      "EarlyStopping counter: 38 out of 100\n",
      "EarlyStopping counter: 39 out of 100\n",
      "EarlyStopping counter: 40 out of 100\n",
      "EarlyStopping counter: 41 out of 100\n",
      "EarlyStopping counter: 42 out of 100\n",
      "EarlyStopping counter: 43 out of 100\n",
      "EarlyStopping counter: 44 out of 100\n",
      "EarlyStopping counter: 45 out of 100\n",
      "EarlyStopping counter: 46 out of 100\n",
      "EarlyStopping counter: 47 out of 100\n",
      "EarlyStopping counter: 48 out of 100\n",
      "EarlyStopping counter: 49 out of 100\n",
      "EarlyStopping counter: 50 out of 100\n",
      "EarlyStopping counter: 51 out of 100\n",
      "EarlyStopping counter: 52 out of 100\n",
      "EarlyStopping counter: 53 out of 100\n",
      "EarlyStopping counter: 54 out of 100\n",
      "EarlyStopping counter: 55 out of 100\n",
      "EarlyStopping counter: 56 out of 100\n",
      "EarlyStopping counter: 57 out of 100\n",
      "EarlyStopping counter: 58 out of 100\n",
      "EarlyStopping counter: 59 out of 100\n",
      "EarlyStopping counter: 60 out of 100\n",
      "EarlyStopping counter: 61 out of 100\n",
      "EarlyStopping counter: 62 out of 100\n",
      "EarlyStopping counter: 63 out of 100\n",
      "EarlyStopping counter: 64 out of 100\n",
      "EarlyStopping counter: 65 out of 100\n",
      "EarlyStopping counter: 66 out of 100\n",
      "EarlyStopping counter: 67 out of 100\n",
      "EarlyStopping counter: 68 out of 100\n",
      "EarlyStopping counter: 69 out of 100\n",
      "EarlyStopping counter: 70 out of 100\n",
      "EarlyStopping counter: 71 out of 100\n",
      "EarlyStopping counter: 72 out of 100\n",
      "EarlyStopping counter: 73 out of 100\n",
      "EarlyStopping counter: 74 out of 100\n",
      "EarlyStopping counter: 75 out of 100\n",
      "EarlyStopping counter: 76 out of 100\n",
      "EarlyStopping counter: 77 out of 100\n",
      "EarlyStopping counter: 78 out of 100\n",
      "EarlyStopping counter: 79 out of 100\n",
      "EarlyStopping counter: 80 out of 100\n",
      "EarlyStopping counter: 81 out of 100\n",
      "EarlyStopping counter: 82 out of 100\n",
      "EarlyStopping counter: 83 out of 100\n",
      "EarlyStopping counter: 84 out of 100\n",
      "EarlyStopping counter: 85 out of 100\n",
      "EarlyStopping counter: 86 out of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▍                                                                  | 1130/10000 [00:01<00:08, 1074.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 87 out of 100\n",
      "EarlyStopping counter: 88 out of 100\n",
      "EarlyStopping counter: 89 out of 100\n",
      "EarlyStopping counter: 90 out of 100\n",
      "EarlyStopping counter: 91 out of 100\n",
      "EarlyStopping counter: 92 out of 100\n",
      "EarlyStopping counter: 93 out of 100\n",
      "EarlyStopping counter: 94 out of 100\n",
      "EarlyStopping counter: 95 out of 100\n",
      "EarlyStopping counter: 96 out of 100\n",
      "EarlyStopping counter: 97 out of 100\n",
      "EarlyStopping counter: 98 out of 100\n",
      "EarlyStopping counter: 99 out of 100\n",
      "EarlyStopping counter: 100 out of 100\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "net = Net()\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.02)\n",
    "\n",
    "# to track the training loss as the model trains\n",
    "t_l = []\n",
    "# to track the validation loss as the model trains\n",
    "d_l = []\n",
    "\n",
    "#initialize the early_stopping object\n",
    "early_stopping = EarlyStopping(patience=100, verbose=True)\n",
    "\n",
    "for epoch in tqdm(range(10000)):# 10000 full passes over the data        \n",
    "    net.zero_grad() # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "    output = net(X_train_1.float()) # pass in the training batch \n",
    "    loss = loss_function(output, y_train_1.float()) # calc and grab the loss value\n",
    "    loss.backward() # apply this loss backwards thru the network's parameters\n",
    "    optimizer.step() # attempt to optimize weights to account for loss/gradients\n",
    "    if epoch%5 == 0: \n",
    "        with torch.no_grad():\n",
    "            y_predict = net(X_dev.float())\n",
    "            dev_error = loss_function(y_predict, y_dev.float())\n",
    "            #print(f'train_loss..:{loss.item()} dev_loss..:{dev_error.item()} ')\n",
    "            t_l.append(loss.item())\n",
    "            d_l.append(dev_error.item())\n",
    "            # early_stopping needs the validation loss to check if it has decresed, \n",
    "            # and if it has, it will make a checkpoint of the current model\n",
    "            early_stopping(dev_error, net)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break  \n",
    "            #print(loss) # print loss. We hope loss (train_loss..:{loss.item()} a measure of wrong-ness) declines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4c26d5df-e2a3-4e61-8b58-11b8022e473b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# evenly sampled time at 200ms intervals\n",
    "#t = np.arange(0., 5., 0.2)\n",
    "\n",
    "# red dashes, blue squares and green triangles\n",
    "plt.plot(t_l,'r--', d_l,'b--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8b942bcc-b30b-4163-991e-8a0022973adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92096.5625\n",
      "(tensor([2570.], dtype=torch.float64), tensor([2518.3364], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2449.], dtype=torch.float64), tensor([2301.2493], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1895.], dtype=torch.float64), tensor([2648.0896], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2411.], dtype=torch.float64), tensor([2230.8508], grad_fn=<UnbindBackward0>))\n",
      "(tensor([3055.], dtype=torch.float64), tensor([2642.9304], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2078.], dtype=torch.float64), tensor([2543.8787], grad_fn=<UnbindBackward0>))\n",
      "(tensor([831.], dtype=torch.float64), tensor([1080.5856], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1494.], dtype=torch.float64), tensor([1527.8843], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2538.], dtype=torch.float64), tensor([2582.1604], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2443.], dtype=torch.float64), tensor([2543.4436], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2380.], dtype=torch.float64), tensor([2329.7830], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2430.], dtype=torch.float64), tensor([2161.7385], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2278.], dtype=torch.float64), tensor([1929.9973], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1852.], dtype=torch.float64), tensor([1730.4014], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2979.], dtype=torch.float64), tensor([2508.8142], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2576.], dtype=torch.float64), tensor([2938.4641], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1920.], dtype=torch.float64), tensor([2202.0466], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2078.], dtype=torch.float64), tensor([2119.0969], grad_fn=<UnbindBackward0>))\n",
      "(tensor([737.], dtype=torch.float64), tensor([1061.9739], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1591.], dtype=torch.float64), tensor([1667.3513], grad_fn=<UnbindBackward0>))\n",
      "0.7403307164855352\n",
      "MAPE for width:  0.12986244364779295\n",
      "MSE for width:  92096.56396814063\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "X_test = torch.tensor(X_test)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "y_predict_1 = net(X_test.float())\n",
    "error = loss_function(y_predict_1, y_test.float())\n",
    "\n",
    "print(error.item())\n",
    "for a in (list(zip(y_test,y_predict_1))):\n",
    "    print(a)\n",
    "    \n",
    "print(r2_score(y_test.detach().numpy()[:,0], y_predict_1.detach().numpy()[:,0]))\n",
    "\n",
    "print('MAPE for width: ', mean_absolute_percentage_error(y_test.detach().numpy()[:,0], y_predict_1.detach().numpy()[:,0]))\n",
    "\n",
    "print('MSE for width: ', mean_squared_error(y_test.detach().numpy()[:,0], y_predict_1.detach().numpy()[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd07a475-663e-4ae4-8d9f-47dbb0767e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "\t\"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "\tdef __init__(self, patience, verbose=False, delta=0, save_path='checkpoint.pt'):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\t\tpatience (int): How long to wait after last time validation loss improved.\n",
    "\t\t\t\t\t\t\tDefault: 7\n",
    "\t\t\tverbose (bool): If True, prints a message for each validation loss improvement.\n",
    "\t\t\t\t\t\t\tDefault: False\n",
    "\t\t\tdelta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "\t\t\t\t\t\t\tDefault: 0\n",
    "\t\t\"\"\"\n",
    "\t\tself.patience = patience\n",
    "\t\tself.verbose = verbose\n",
    "\t\tself.counter = 0\n",
    "\t\tself.best_score = None\n",
    "\t\tself.early_stop = False\n",
    "\t\tself.val_loss_min = np.inf\n",
    "\t\tself.delta = delta\n",
    "\t\tself.save_path = save_path\n",
    "\t\tos.makedirs(pathlib.Path(self.save_path).parent, exist_ok=True)\n",
    "\n",
    "\tdef __call__(self, val_loss, model):\n",
    "\n",
    "\t\tscore = -val_loss\n",
    "\n",
    "\t\tif self.best_score is None:\n",
    "\t\t\tself.best_score = score\n",
    "\t\t\tself.save_checkpoint(val_loss, model)\n",
    "\t\telif score < self.best_score - self.delta:\n",
    "\t\t\tself.counter += 1\n",
    "\t\t\tprint(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "\t\t\tif self.counter >= self.patience:\n",
    "\t\t\t\tself.early_stop = True\n",
    "\t\telse:\n",
    "\t\t\tself.best_score = score\n",
    "\t\t\tself.save_checkpoint(val_loss, model)\n",
    "\t\t\tself.counter = 0\n",
    "\n",
    "\tdef save_checkpoint(self, val_loss, model):\n",
    "\t\t\"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "\t\tif self.verbose:\n",
    "\t\t\tprint(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "\t\ttorch.save(model.state_dict(), self.save_path)\n",
    "\t\tself.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d3cc3eb6-13d9-461a-9652-9037883221f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.8129e+00, 1.2348e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 2.5266e+00, 1.6963e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 2.1053e+00, 1.4225e+00,\n",
       "         0.0000e+00],\n",
       "        [2.0000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 7.1144e-01, 4.9267e-01,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 2.6967e-01, 1.7533e-01,\n",
       "         5.0000e+01],\n",
       "        [2.5000e+01, 4.7000e-01, 2.0000e+01, 2.0000e+01, 3.2609e+00, 1.3792e+00,\n",
       "         0.0000e+00],\n",
       "        [3.0000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 2.8456e+00, 1.8818e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 5.0000e+01, 2.3254e+00, 1.6061e+00,\n",
       "         0.0000e+00],\n",
       "        [3.0000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 2.3681e+00, 1.6029e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 2.6037e+00, 1.7530e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 3.0000e+01, 2.0000e+01, 2.8984e+00, 1.5256e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.9986e+00, 1.3608e+00,\n",
       "         1.0000e+02],\n",
       "        [2.0000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.4334e+00, 9.6971e-01,\n",
       "         0.0000e+00],\n",
       "        [2.0000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.9013e+00, 1.2903e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.5422e+00, 1.0346e+00,\n",
       "         5.0000e+01],\n",
       "        [2.5000e+01, 9.5000e-01, 5.0000e+01, 2.0000e+01, 1.4006e-01, 8.7313e-02,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.1569e+00, 7.9836e-01,\n",
       "         1.0000e+02],\n",
       "        [2.0000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.6207e+00, 1.1113e+00,\n",
       "         0.0000e+00],\n",
       "        [3.0000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 2.7387e-01, 1.7880e-01,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.9150e+00, 1.3685e+00,\n",
       "         1.0000e+02],\n",
       "        [2.5000e+01, 4.7000e-01, 3.0000e+01, 2.0000e+01, 2.2827e+00, 1.1935e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 2.0000e+01, 2.0000e+01, 3.0107e+00, 1.2733e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.5983e+00, 1.0751e+00,\n",
       "         2.5000e+01],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 6.6971e-01, 4.4443e-01,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.0255e+00, 6.8475e-01,\n",
       "         2.5000e+01],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 4.0043e-01, 2.6357e-01,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.9184e+00, 1.2996e+00,\n",
       "         0.0000e+00],\n",
       "        [2.2000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.0327e+00, 6.9429e-01,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 3.0000e+01, 2.0000e+01, 2.0046e+00, 1.0549e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 2.4399e+00, 1.6475e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 9.5000e-01, 5.0000e+01, 2.0000e+01, 1.2707e-01, 7.9500e-02,\n",
       "         0.0000e+00],\n",
       "        [3.0000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.4076e+00, 9.4194e-01,\n",
       "         0.0000e+00],\n",
       "        [3.0000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 7.5650e-01, 4.8531e-01,\n",
       "         0.0000e+00],\n",
       "        [3.0000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 9.0887e-01, 5.9680e-01,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 8.0000e+00, 1.5277e+00, 1.0200e+00,\n",
       "         0.0000e+00],\n",
       "        [1.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.1776e+00, 8.0164e-01,\n",
       "         0.0000e+00],\n",
       "        [2.2000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 7.0407e-01, 4.6864e-01,\n",
       "         0.0000e+00],\n",
       "        [2.2000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 4.4050e-01, 3.0313e-01,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 5.0000e+01, 1.7771e+00, 1.2187e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 8.9386e-01, 6.0193e-01,\n",
       "         0.0000e+00],\n",
       "        [2.0000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.5719e+00, 1.0775e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 2.0000e+01, 2.0000e+01, 3.3295e+00, 1.3975e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 3.0000e+01, 2.0000e+01, 2.3506e+00, 1.2636e+00,\n",
       "         0.0000e+00],\n",
       "        [3.0000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 2.5547e+00, 1.6876e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.3487e+00, 8.9613e-01,\n",
       "         1.0000e+02],\n",
       "        [2.5000e+01, 9.5000e-01, 5.0000e+01, 2.0000e+01, 1.1636e-01, 7.2643e-02,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.5765e+00, 1.1421e+00,\n",
       "         1.0000e+02],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.5131e+00, 1.0168e+00,\n",
       "         1.0000e+02],\n",
       "        [2.5000e+01, 4.7000e-01, 2.0000e+01, 2.0000e+01, 3.1987e+00, 1.3488e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 8.0000e+00, 1.4937e+00, 9.8714e-01,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.1434e+00, 7.6125e-01,\n",
       "         0.0000e+00],\n",
       "        [1.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.2533e+00, 8.5627e-01,\n",
       "         0.0000e+00],\n",
       "        [3.0000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 3.3220e-01, 2.1820e-01,\n",
       "         0.0000e+00],\n",
       "        [2.0000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 5.2133e-01, 3.5464e-01,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.0009e+00, 6.9400e-01,\n",
       "         2.5000e+01],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 9.3837e-01, 6.2394e-01,\n",
       "         5.0000e+01],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 1.5965e+00, 1.0639e+00,\n",
       "         5.0000e+01],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 8.4225e-01, 5.5563e-01,\n",
       "         5.0000e+01],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 2.1873e+00, 1.4718e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 3.0000e+01, 2.0000e+01, 2.0452e+00, 1.1366e+00,\n",
       "         0.0000e+00],\n",
       "        [2.5000e+01, 4.7000e-01, 5.0000e+01, 8.0000e+00, 1.7726e+00, 1.1855e+00,\n",
       "         0.0000e+00],\n",
       "        [2.2000e+01, 4.7000e-01, 5.0000e+01, 2.0000e+01, 7.6507e-01, 5.1107e-01,\n",
       "         0.0000e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
