{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3212399a-6b38-4453-b9fb-89d1694041f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "45472a20-0887-4ef6-ab85-ad32790835bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Flow rate</th>\n",
       "      <th>Duty cycle</th>\n",
       "      <th>Pulse period</th>\n",
       "      <th>Laser energy</th>\n",
       "      <th>cavity width(mm)</th>\n",
       "      <th>cavity depth(µm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>68.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2108.0</td>\n",
       "      <td>67.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2233.0</td>\n",
       "      <td>61.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>52.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Voltage  Flow rate  Duty cycle  Pulse period  Laser energy  \\\n",
       "0       25       0.47          20            20             0   \n",
       "1       25       0.47          20            20             0   \n",
       "2       25       0.47          20            20             0   \n",
       "3       25       0.47          20            20             0   \n",
       "4       25       0.47          20            20             0   \n",
       "\n",
       "   cavity width(mm)  cavity depth(µm)  \n",
       "0            2285.0              72.1  \n",
       "1            2199.0              68.2  \n",
       "2            2108.0              67.2  \n",
       "3            2233.0              61.2  \n",
       "4            2046.0              52.2  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x1 input\n",
    "\n",
    "df = pd.read_csv('datasets/CNN_parameter_dataset.csv', encoding='utf-8')\n",
    "int_flow = df.copy()\n",
    "\n",
    "#preparing the dataset for spliting into features and labels \n",
    "int_flow.columns = [col.strip() for col in df.columns]\n",
    "int_flow.drop(['Sample','Cavity','Pulse width'], axis=1, inplace=True)\n",
    "int_flow.drop(['Pulse rms','Pulse pkpk'], axis=1, inplace=True)\n",
    "int_flow['cavity width(mm)'] = int_flow['cavity width(mm)']*1000\n",
    "#int_flow = sklearn.utils.shuffle(int_flow)\n",
    "int_flow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "37b9866d-7290-4e20-a4f7-276a23e51254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x2 input\n",
    "\n",
    "X2= []\n",
    "path = r'C:\\Users\\nikam\\Desktop\\Academics\\Thesis\\Internal_flow_experiments\\Internal_flow_current_data'   \n",
    "for folder in (os.listdir(path)):\n",
    "    dfs = []\n",
    "    \n",
    "    for file in (os.listdir(path + '\\\\'+folder)):\n",
    "        df = pd.read_csv(path + '\\\\'+folder + '\\\\'+file, encoding='unicode_escape', sep='\\t' )\n",
    "        dfs.append(df)\n",
    "    new_df = pd.concat(dfs)\n",
    "    for i in range(0,len(new_df),15):\n",
    "        _df = new_df[i:i+15].copy()\n",
    "        _df = _df.reset_index(drop=True)\n",
    "        idx = _df['Pulse rms [A]'].index[_df['Pulse rms [A]'].apply(np.isnan)]\n",
    "        \n",
    "        if len(idx)>0: \n",
    "            for ii in idx:\n",
    "                if ii == 0: \n",
    "                    replacing_val = _df['Pulse rms [A]'][ii+1]\n",
    "                elif ii == 14:\n",
    "                     replacing_val = _df['Pulse rms [A]'][ii-1]   \n",
    "                else:\n",
    "                    replacing_val = (_df['Pulse rms [A]'][ii-1]+_df['Pulse rms [A]'][ii+1])/2\n",
    "                _df.loc[ii,'Pulse rms [A]'] = replacing_val\n",
    "        X2.append(_df.iloc[:,1:].to_numpy())        \n",
    "        \n",
    "X2 = np.asarray(X2, dtype=np.float16)\n",
    "X2 =np.expand_dims(X2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c09579e0-a38c-4ca0-9df8-067153c4d049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TC1 [ºC]</th>\n",
       "      <th>TC2 [ºC]</th>\n",
       "      <th>TC3 [ºC]</th>\n",
       "      <th>IR Temp [ºC]</th>\n",
       "      <th>Pulse pkpk [A]</th>\n",
       "      <th>Pulse rms [A]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.365</td>\n",
       "      <td>22.002</td>\n",
       "      <td>24.460</td>\n",
       "      <td>25.106</td>\n",
       "      <td>2.425</td>\n",
       "      <td>1.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.360</td>\n",
       "      <td>22.040</td>\n",
       "      <td>24.421</td>\n",
       "      <td>23.502</td>\n",
       "      <td>2.449</td>\n",
       "      <td>1.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.378</td>\n",
       "      <td>21.989</td>\n",
       "      <td>24.212</td>\n",
       "      <td>23.633</td>\n",
       "      <td>2.450</td>\n",
       "      <td>1.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.342</td>\n",
       "      <td>22.025</td>\n",
       "      <td>24.193</td>\n",
       "      <td>24.773</td>\n",
       "      <td>2.431</td>\n",
       "      <td>1.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.329</td>\n",
       "      <td>22.023</td>\n",
       "      <td>24.100</td>\n",
       "      <td>24.816</td>\n",
       "      <td>2.457</td>\n",
       "      <td>1.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.328</td>\n",
       "      <td>22.077</td>\n",
       "      <td>24.088</td>\n",
       "      <td>24.549</td>\n",
       "      <td>2.426</td>\n",
       "      <td>1.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22.361</td>\n",
       "      <td>22.080</td>\n",
       "      <td>24.058</td>\n",
       "      <td>22.987</td>\n",
       "      <td>2.212</td>\n",
       "      <td>1.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.356</td>\n",
       "      <td>22.007</td>\n",
       "      <td>24.246</td>\n",
       "      <td>22.119</td>\n",
       "      <td>2.321</td>\n",
       "      <td>1.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.396</td>\n",
       "      <td>21.970</td>\n",
       "      <td>24.286</td>\n",
       "      <td>24.091</td>\n",
       "      <td>2.296</td>\n",
       "      <td>1.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.347</td>\n",
       "      <td>21.994</td>\n",
       "      <td>24.373</td>\n",
       "      <td>25.165</td>\n",
       "      <td>2.342</td>\n",
       "      <td>1.586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.349</td>\n",
       "      <td>21.983</td>\n",
       "      <td>24.182</td>\n",
       "      <td>23.318</td>\n",
       "      <td>2.296</td>\n",
       "      <td>1.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22.353</td>\n",
       "      <td>22.038</td>\n",
       "      <td>24.160</td>\n",
       "      <td>21.970</td>\n",
       "      <td>2.353</td>\n",
       "      <td>1.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22.338</td>\n",
       "      <td>22.057</td>\n",
       "      <td>24.152</td>\n",
       "      <td>21.795</td>\n",
       "      <td>2.484</td>\n",
       "      <td>1.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22.370</td>\n",
       "      <td>22.043</td>\n",
       "      <td>24.185</td>\n",
       "      <td>23.383</td>\n",
       "      <td>2.500</td>\n",
       "      <td>1.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22.319</td>\n",
       "      <td>22.021</td>\n",
       "      <td>23.974</td>\n",
       "      <td>24.718</td>\n",
       "      <td>2.079</td>\n",
       "      <td>1.399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TC1 [ºC]  TC2 [ºC]  TC3 [ºC]  IR Temp [ºC]  Pulse pkpk [A]  Pulse rms [A]\n",
       "0     22.365    22.002    24.460        25.106           2.425          1.632\n",
       "1     22.360    22.040    24.421        23.502           2.449          1.657\n",
       "2     22.378    21.989    24.212        23.633           2.450          1.658\n",
       "3     22.342    22.025    24.193        24.773           2.431          1.640\n",
       "4     22.329    22.023    24.100        24.816           2.457          1.662\n",
       "5     22.328    22.077    24.088        24.549           2.426          1.638\n",
       "6     22.361    22.080    24.058        22.987           2.212          1.497\n",
       "7     22.356    22.007    24.246        22.119           2.321          1.579\n",
       "8     22.396    21.970    24.286        24.091           2.296          1.557\n",
       "9     22.347    21.994    24.373        25.165           2.342          1.586\n",
       "10    22.349    21.983    24.182        23.318           2.296          1.560\n",
       "11    22.353    22.038    24.160        21.970           2.353          1.599\n",
       "12    22.338    22.057    24.152        21.795           2.484          1.688\n",
       "13    22.370    22.043    24.185        23.383           2.500          1.692\n",
       "14    22.319    22.021    23.974        24.718           2.079          1.399"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a8e45932-ebb8-4424-ad03-fd5853050573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing X(features) and y(labels)\n",
    "X1 = int_flow.drop(['cavity width(mm)','cavity depth(µm)'], axis=1).to_numpy()\n",
    "#X1 =np.expand_dims(X1,axis=1)\n",
    "y = int_flow[['cavity width(mm)']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e99af64b-9bab-4fc5-b0aa-a6a4f83e2b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X1_train, X1_test,X2_train, X2_test, y_train, y_test = model_selection.train_test_split(X1, X2, y, test_size=0.2, random_state=5)\n",
    "X1_train_1, X1_dev, X2_train_1, X2_dev, y_train_1, y_dev = model_selection.train_test_split(X1_train, X2_train, y_train, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5658fdc4-2264-47c5-aa50-2c2fbb123e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nncnn(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(5, 10)        \n",
    "        self.cnn1 = nn.Conv2d(1, 5, (2,2))\n",
    "        \n",
    "        self.fc2 = nn.Linear(360, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "        self.fc4 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x1,x2):\n",
    "        x1 = F.relu(self.fc1(x1))\n",
    "        \n",
    "        x2 = self.cnn1(x2).view(x1.size(0),-1)\n",
    "        #print(x1.shape, x2.shape)\n",
    "        x_joined = torch.cat([x1,x2], dim=1)\n",
    "        #print(x1.shape, x2.shape, x_joined.shape)\n",
    "        x_joined = F.relu(self.fc2(x_joined))\n",
    "        x_joined = F.relu(self.fc3(x_joined))\n",
    "        x_joined = self.fc4(x_joined)\n",
    "\n",
    "        return x_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "36549066-84ab-4342-9039-a60c2547d50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nncnn(\n",
       "  (fc1): Linear(in_features=5, out_features=10, bias=True)\n",
       "  (cnn1): Conv2d(1, 5, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (fc2): Linear(in_features=360, out_features=50, bias=True)\n",
       "  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (fc4): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nncnn()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "74ce8085-14e2-4b7e-9a1e-bfdf251ec665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the neuralnetwork model\n",
    "\n",
    "X1_train_1 = torch.tensor(X1_train_1, dtype=torch.float64)\n",
    "X2_train_1 = torch.tensor(X2_train_1, dtype=torch.float64)\n",
    "y_train_1 = torch.tensor(y_train_1)\n",
    "\n",
    "X1_dev = torch.tensor(X1_dev, dtype=torch.float64)\n",
    "X2_dev = torch.tensor(X2_dev, dtype=torch.float64)\n",
    "y_dev = torch.tensor(y_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fb33d217-a28c-41cc-889e-ec2722e8481c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                             | 66/10000 [00:00<00:29, 339.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 4765881.500000).  Saving model ...\n",
      "Validation loss decreased (4765881.500000 --> 1575653.250000).  Saving model ...\n",
      "Validation loss decreased (1575653.250000 --> 908012.062500).  Saving model ...\n",
      "Validation loss decreased (908012.062500 --> 723267.687500).  Saving model ...\n",
      "Validation loss decreased (723267.687500 --> 403865.531250).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (403865.531250 --> 329844.562500).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (329844.562500 --> 321013.906250).  Saving model ...\n",
      "Validation loss decreased (321013.906250 --> 292539.656250).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (292539.656250 --> 291060.562500).  Saving model ...\n",
      "Validation loss decreased (291060.562500 --> 287578.937500).  Saving model ...\n",
      "Validation loss decreased (287578.937500 --> 283495.343750).  Saving model ...\n",
      "Validation loss decreased (283495.343750 --> 281971.406250).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▏                                                                           | 150/10000 [00:00<00:25, 387.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (281971.406250 --> 279936.375000).  Saving model ...\n",
      "Validation loss decreased (279936.375000 --> 277517.093750).  Saving model ...\n",
      "Validation loss decreased (277517.093750 --> 272883.000000).  Saving model ...\n",
      "Validation loss decreased (272883.000000 --> 263221.250000).  Saving model ...\n",
      "Validation loss decreased (263221.250000 --> 246586.156250).  Saving model ...\n",
      "Validation loss decreased (246586.156250 --> 224016.750000).  Saving model ...\n",
      "Validation loss decreased (224016.750000 --> 198917.062500).  Saving model ...\n",
      "Validation loss decreased (198917.062500 --> 177117.984375).  Saving model ...\n",
      "Validation loss decreased (177117.984375 --> 162130.250000).  Saving model ...\n",
      "Validation loss decreased (162130.250000 --> 152869.812500).  Saving model ...\n",
      "Validation loss decreased (152869.812500 --> 147545.734375).  Saving model ...\n",
      "Validation loss decreased (147545.734375 --> 144806.796875).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                           | 192/10000 [00:00<00:24, 395.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 50\n",
      "Validation loss decreased (144806.796875 --> 144409.406250).  Saving model ...\n",
      "Validation loss decreased (144409.406250 --> 143910.828125).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "EarlyStopping counter: 9 out of 50\n",
      "EarlyStopping counter: 10 out of 50\n",
      "EarlyStopping counter: 11 out of 50\n",
      "EarlyStopping counter: 12 out of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██                                                                           | 270/10000 [00:00<00:26, 366.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 13 out of 50\n",
      "EarlyStopping counter: 14 out of 50\n",
      "EarlyStopping counter: 15 out of 50\n",
      "EarlyStopping counter: 16 out of 50\n",
      "EarlyStopping counter: 17 out of 50\n",
      "EarlyStopping counter: 18 out of 50\n",
      "EarlyStopping counter: 19 out of 50\n",
      "EarlyStopping counter: 20 out of 50\n",
      "EarlyStopping counter: 21 out of 50\n",
      "EarlyStopping counter: 22 out of 50\n",
      "EarlyStopping counter: 23 out of 50\n",
      "EarlyStopping counter: 24 out of 50\n",
      "EarlyStopping counter: 25 out of 50\n",
      "EarlyStopping counter: 26 out of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▋                                                                          | 342/10000 [00:00<00:29, 329.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 27 out of 50\n",
      "EarlyStopping counter: 28 out of 50\n",
      "EarlyStopping counter: 29 out of 50\n",
      "EarlyStopping counter: 30 out of 50\n",
      "EarlyStopping counter: 31 out of 50\n",
      "EarlyStopping counter: 32 out of 50\n",
      "EarlyStopping counter: 33 out of 50\n",
      "EarlyStopping counter: 34 out of 50\n",
      "EarlyStopping counter: 35 out of 50\n",
      "EarlyStopping counter: 36 out of 50\n",
      "EarlyStopping counter: 37 out of 50\n",
      "EarlyStopping counter: 38 out of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                         | 420/10000 [00:01<00:28, 338.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 39 out of 50\n",
      "EarlyStopping counter: 40 out of 50\n",
      "EarlyStopping counter: 41 out of 50\n",
      "EarlyStopping counter: 42 out of 50\n",
      "EarlyStopping counter: 43 out of 50\n",
      "EarlyStopping counter: 44 out of 50\n",
      "EarlyStopping counter: 45 out of 50\n",
      "EarlyStopping counter: 46 out of 50\n",
      "EarlyStopping counter: 47 out of 50\n",
      "EarlyStopping counter: 48 out of 50\n",
      "EarlyStopping counter: 49 out of 50\n",
      "EarlyStopping counter: 50 out of 50\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "net = nncnn()\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.02)\n",
    "\n",
    "# to track the training loss as the model trains\n",
    "t_l = []\n",
    "# to track the validation loss as the model trains\n",
    "d_l = []\n",
    "\n",
    "#initialize the early_stopping object\n",
    "early_stopping = EarlyStopping(patience=50, verbose=True)\n",
    "\n",
    "for epoch in tqdm(range(10000)):# 10000 full passes over the data        \n",
    "    net.zero_grad() # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "    output = net(X1_train_1.float(), X2_train_1.float()) # pass in the training batch \n",
    "    loss = loss_function(output, y_train_1.float()) # calc and grab the loss value\n",
    "    loss.backward() # apply this loss backwards thru the network's parameters\n",
    "    optimizer.step() # attempt to optimize weights to account for loss/gradients\n",
    "    if epoch%5 == 0: \n",
    "        with torch.no_grad():\n",
    "            y_predict = net(X1_dev.float(), X2_dev.float())\n",
    "            dev_error = loss_function(y_predict, y_dev.float())\n",
    "            #print(f'train_loss..:{loss.item()} dev_loss..:{dev_error.item()} ')\n",
    "            t_l.append(loss.item())\n",
    "            d_l.append(dev_error.item())\n",
    "            # early_stopping needs the validation loss to check if it has decresed, \n",
    "            # and if it has, it will make a checkpoint of the current model\n",
    "            early_stopping(dev_error, net)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break  \n",
    "            #print(loss) # print loss. We hope loss (train_loss..:{loss.item()} a measure of wrong-ness) declines!\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0ff20ffc-f2f7-4498-a681-5b9359d3d58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEDCAYAAAAcI05xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAg+UlEQVR4nO3deXhcZd3/8fc3a9N9S7cU2tIWChTKEnZUnkqhbIpessqiiKCigA+CKDyPohUR+wNBEGVTEGlRWR8ohYIgtJQlBcpSKlBaaAt0oUu6Zf/+/rhnOkmbNqFkcu50Pq/rmiuZuefMfHNy5jP33HOfc8zdERGReOUlXYCIiGydglpEJHIKahGRyCmoRUQip6AWEYmcglpEJHJZC2ozu93MlprZG628/4lmNsfM3jSzu7NVl4hIR2PZmkdtZp8H1gJ3uvvoFu47Evg7MNbdV5pZP3dfmpXCREQ6mKz1qN39GWBF49vMbLiZTTWzWWb2rJmNSjV9G7jR3VemllVIi4iktPcY9c3AD9x9X+BHwB9St+8M7GxmM8zseTMb3851iYhEq6C9nsjMugIHA/8ws/TNxY3qGAkcBgwGnjGzPdx9VXvVJyISq3YLakLvfZW779VM2yLgBXevBeab2duE4H6pHesTEYlSuw19uHslIYRPALBgTKr5AUJvGjPrSxgKea+9ahMRiVmrgtrMFpjZ62b2qplVtHKZScBMYBczW2Rm3wK+DnzLzGYDbwJfTt39MeATM5sDPAVc7O6ffNo/RkRke9Sq6XlmtgAod/flWa9IRESa0J6JIiKRa22Pej6wEnDgT+5+czP3OQc4B6BLly77jho1atO7iIjIFsyaNWu5u5c219baoC5z98Vm1g+YRpgL/cyW7l9eXu4VFa0ayhYREcDMZrl7eXNtrRr6cPfFqZ9LgfuB/duuPBER2ZoWg9rMuphZt/TvwBFAqw60JCIin11rdnjpD9yf2puwALjb3admtSoREdmoxaB29/eAMS3dT0REskPT80REIqegFhGJnIJaRCRyCmoRkchFFdRHH7qa63+mYzGJiDQWVVC/8Fw9b9//ZtJliIhEJaqgLrJaqquTrkJEJC5RBXVxXi01tUlXISISl8iCuo7qGmv5jiIiOaQ9z5nYor26vsvQQn2ZKCLSWFRBfc/fDYoGJV2GiEhUogpqvvjFpCsQEYlOVGPU3zt5BWeOX5J0GSIiUYmqR71g+kKWLYNwZFUREYHIetTFRU51fWHSZYiIRCW+oG6IqpMvIpK4qIK6qMio9iJoxQl3RURyRVRBvUfZCg7kebQfuYhIRlTjDBffOBTea4CCqMoSEUlUXIm4007hIiIiG0U19HHtz1cxYsBaWL066VJERKIRVVBXzv2QeUu6Uj9vQdKliIhEI6qgLu6cD0BNZVXClYiIxCOyoA5D5tWrFdQiImlxBXUXBbWIyKaimvUxYgR8hfso0MkDREQ2iiqojzitH0eMHgg775x0KSIi0YgqqCkpgYMOSroKEZGoRDVG/fij9ZR2q+LVe/6TdCkiItGIKqjdYfnaTqyfNiPpUkREohFVUBeVhHnU1evrE65ERCQeUQV1cXH4WbO+LtlCREQiEmVQq0ctIpLR6qA2s3wze8XMHs5WMf36wend7mdQ3sfZegoRkQ7n00zPuwB4C+iepVrYYQe4s2J36HpAtp5CRKTDaVWP2swGA8cAt2a3HMLOLoMGZf1pREQ6itYOffwOuARo2NIdzOwcM6sws4ply5ZtUzHLlkGnonpuOuulbVpeRGR71GJQm9mxwFJ3n7W1+7n7ze5e7u7lpaWl21RMYSFU1+ZTNe3ZbVpeRGR71Joe9SHAl8xsATAZGGtmd2WjmI2zPnRuWxGRjVoManf/ibsPdvehwMnAv9z9tGwUszGodfQ8EZGNoppHnZcHBXn1CmoRkUY+VVC7+9Pufmy2igH43pgZHNAwM5tPISLSocR1mFPguidGQ/Xvki5DRCQa0QV1XffeNDRAUdKFiIhEIqoxaoCRQ6r59n6vwrp1SZciIhKF6IK6qH4D1a/NhZUrky5FRCQK0QV1cZFTTTFs2JB0KSIiUYgwqAlBvX590qWIiEQhvqAuVlCLiDQWXVCfftRyTmayglpEJMXcvc0ftLy83CsqKrZt4dpaqKqCLl3CrooiIjnAzGa5e3lzbdHNo15bXUhNbSG9ldEiIkCEQx9nn1HDwSOWwkztRi4iAhEGdXFhPdUr18ErryRdiohIFOIL6s75mvUhItJIdEFdVFKgoBYRaSS6oC4uydOeiSIijUQ36+OYY2DAH67W+bhERFKiC+qxY2Hs2p9Bfn7SpYiIRCG6oY/KSpi3IJ+GhqQrERGJQ3RBfeutMGIEVF79x6RLERGJQnRBvfFM5FOfSrYQEZFIxBvU6+uTLUREJBIKahGRyCmoRUQiF11Q77sv3HDw3QzoXJl0KSIiUYhuHvXw4XDejFOBU5MuRUQkCtH1qNetg9mzw3xqERGJMKhnz4a99oKZx0yALJx9RkSko4kuqDd+mTj9RaipSbYYEZEIxBvUOtSpiAigoBYRiZ6CWkQkctEFdd++8OcLZ/P5ge9CvXZ6ERExz8LMivLycq+oqGjzxxUR2V6Z2Sx3L2+urcUetZl1MrMXzWy2mb1pZle0fYkZDQ0wYwa8/342n0VEpONozdBHNTDW3ccAewHjzezAbBXkDoceCnd88U547rlsPY2ISIfR4i7kHsZG1qauFqYuWdsTJT8f8vOd6nkLYVGnbD2NiEiH0aovE80s38xeBZYC09z9hWwWVVzkmvUhIpLSqqB293p33wsYDOxvZqM3vY+ZnWNmFWZWsWzZss9UVHGxpueJiKR9qul57r4KeAoY30zbze5e7u7lpaWln6mo4mKooUhBLSJC62Z9lJpZz9TvJcA4YG42i7rtFue7Q6dC9+7ZfBoRkQ6hNcejHgjcYWb5hGD/u7s/nM2ijj4uH467P5tPISLSYbRm1sdrwN7tUMtGzz0HhYWw337t+awiInGKbhdygPPPh58fNwsmTEi6FBGRxEUZ1MXFUF1ZBXOzOhQuItIhxBvUVqJZHyIiRB3UmkctIgIxBzWdFNQiIrRuel67u+IKqC55CLruknQpIiKJizKox4wBJv0w6TJERKIQ5dDHyy/D/drfRUQEiDSob78dzv76ejjkkKRLERFJXJRBXVwM1XX58NprSZciIpK4KIO6qAhq6vPDrI8snNNRRKQjiTKoi4uhtqGAhgaHmpqkyxERSVS0QQ06JrWICEQ6Pe+MM+Dw4mconHa4hj5EJOeZZyEIy8vLvaKios0fV0Rke2Vms9y9vLm2KIc+3nkHbr4Z1qxJuhIRkeRFGdTPPw/nngtLRh4K06YlXY6ISKKiDOr0l4nVS1bCkiXJFiMikrC4g5piWL482WJERBIWd1DndVZQi0jOizKoi4rCz+rupbBsWbLFiIgkLMp51AccAG+9BTtetxOMGZl0OSIiiYoyqLt0gVGjgJv+X9KliIgkLsqhjxUr4JprUich156JIpLjogzq5cvhooug4r/vhkGDki5HRCRRUQb1xoMy5ZfA0qXQ0JBsQSIiCYo6qKs79QghvXJlsgWJiCQo8qDuHn7RXGoRyWFxB3WRglpEJMrpeSUlsHAh9FpVCJ2/D336JF2SiEhiogxqMxg8GBg8DH7/+6TLERFJVJRDHwC/+Q08+ihQW6vTcYlITos6qKdMAXr1gv/936TLERFJTItBbWY7mNlTZjbHzN40swvao7DiYqiuJoxP68tEEclhrRmjrgMucveXzawbMMvMprn7nGwWVlSUCupSHUFPRHJbiz1qd//I3V9O/b4GeAsoy3ZhxcVQUwP07asetYjktE81Rm1mQ4G9gReyUk0jG4c++vZVj1pEclqrp+eZWVfgXuBCd69spv0c4ByAHXfc8TMX9txzqRMITD0Byps9g7qISE4wb8VhRM2sEHgYeMzdr2np/uXl5V5RUdEG5YmI5AYzm+XuzfZKWzPrw4DbgLdaE9Jt5eab4frrCeMfCxakBqxFRHJPa8aoDwFOB8aa2aupy9FZrov774e77gIeeQSGDUudRUBEJPe0OEbt7tMBa4dammjyZSLoC0URyVnR7pm4WVBrip6I5KiOE9TqUYtIjoo6qGtrgd69w+H01KMWkRwV5WFOAf70J8jLAygI0z/22y/pkkREEhFtUOc17ut///uJ1SEikrRohz4efBDOPTd15YMP4M03E61HRCQp0Qb1K6+EnV4aGoAf/ABOPTXpkkREEhFtUKdPcKsj6IlIros+qDcek3r5cmjFcUlERLY3HSOo+/YNXeu1axOtSUQkCdEGdZcu0L17ai51aWm4UTu9iEgOijaov/ENWL0aysqAL3wBJk3K7KUoIpJDop1H3cTQoeEiIpKDou1RL1wIJ54I06cTxqefeiocl1pEJMdEG9RFRfCPf8DLLwNVVTB2LNx7b9JliYi0u2iDul8/6NwZ5s8HunWDwkLNpRaRnBRtUJuFYen581NXdDZyEclR0QY1hDNwzZ+fupLe6UVEJMdEPetjzz1hzZrUFfWoRSRHRR3UV165yZWCqMsVEcmKjpN8BxyQdAUiIomIeox64UI4+GCYMoUwh/quu2DDhqTLEhFpV1EHdY8eMHNm6pwB06fD6aeH9BYRySFRB3X37uHctvPnAwMHhhs/+ijRmkRE2lvUQQ1hit5776GgFpGc1SGCWj1qEcll0c/6OOSQsGMiPXuGswkoqEUkx0Qf1BdeGC5g8NxzMHhwsgWJiLSz6IO6iX32SboCEZF2F/0Y9cKFoRP9t78Rjkl9yy1JlyQi0q6iD+rSUli8GObNIxyg+tJLky5JRKRdRR/UnTrBoEGNZn6sWJE6NbmISG6IPqih0XGp01P0lixJshwRkXbVIYJac6lFJJe1OOvDzG4HjgWWuvvo7Je0ufHjw67kPmAgBgpqEckp5u5bv4PZ54G1wJ2tDery8nKvqKhog/I2UVMTTh7Qv7+OTS0i2xUzm+Xu5c21tTj04e7PACvavKpPqbYWqhqKoKxMIS0iOaXNxqjN7BwzqzCzimVtfMqsxYuhpAT++lfg+uvh7rvb9PFFRGLWZkHt7je7e7m7l5eWlrbVwwIwYEA43sf8+cDtt8OkSW36+CIiMesQsz7y82HHHRvN/NCXiSKSQzpEUAMMHw6vvhpmfvDxx0mXIyLSbloMajObBMwEdjGzRWb2reyXtblTToG5c+HxDZ8LO7w0NCRRhohIu2tx+oS7n9IehbTk618PM/PKG+rgHw1hV/K+fZMuS0Qk61qcR70tsjaPGsJc6vz8cBER2U58pnnUsXn48SIu/5lCWkRyR4cL6uefruLKXzXwnzueT7oUEZF20eGC+vzz6immmok3dEq6FBGRdtHhgrrfsC6cVXgXd748mg8/TLoaEZHs63BBDXBR2WRqGgq4886kKxERyb4OGdQ7DannrP4PM2RI0pWIiGRfxzwM3Y47clvdVXDKsUlXIiKSdR0zqFNjHpWVUFUF/folXI+ISBZ1yKEPCOe3HTQIrr466UpERLKrYwb1889T/LXj2H/PKqZNS7oYEZHs6phBvXYtPPww40Z/yGuv6aTkIrJ965hBnTob+bjS2QA88USSxYiIZFfHDOqhQ2HgQPa+8mv0Lqxk2oPrk65IRCRrOmZQd+kCr79O/i+v4C9ll/Pjn6YO0lRTk2xdIiJZ0DGDGqBPH7j8co577zp23asY1q2DMWPgl78MpywXEdlOdNygTnGMyZPhiWnOG8OO46r/XYfvfwB3/3Yxb76ZdHUiIp9dxztxQDNGjoS8PPjwQ+hWuIFn+AIHVD7Onp/rwb/+ZZi1WykiIttkuzpxQHPGjYO334Zdd4WKN0oYceMP+VX9pTz9tHHPPUlXJyLy2WwXQX3ppfDb38K//x32VuSkk/j2Nbuxz5g6LroI1qxJukIRkW23XQT1jjvCj34EJSWpG/LyyP/h+dz4xwI+/BAmTMjct7o6XEREOortIqi35MANT3HZyL9zYHkdAGeeCZ06QeeSBnbdYQ0nnuhMmAB1dQkXKiKyFR3z6HmttXYtE945CVbfAq+W86WjdmfkiHxq/nArry8q5eWHynnv1e5cfll3wLj99jB0kpcXZvutWxf2rTn00PBwc+aEXnvnzpmLToYuItm2Xcz62CJ3OPBAeOedMFB9+eXws5+FLvSdd8IvfkH9+wvJ32UktROvY8CZR7JiRdOHOPv4Zdxyax7eqzcFhUZDQ9P2iy6CiRNDqO+3HxQUQGFh+FlUBGedBd/8JqxaBeeeG3r0xcXQtSt07w7jx4cSa2pCmYMHQ48e7baGRCQSW5v1sX33qM3gyivDtJATToDzzw+3FxSEBD3tNPL/+leYNInCfr1YsAAqfv4wxb+fSOfaVXRhHT0fWAUPLKdh7jvcc88I1k1/hfWvz2Nd94GsK+nDAX2r4PkqbPT+jB6dR211A3UNRm2tUVMTeucAGzbA7NlhfLyqKgT7mjXQu3fmvWT06HDf0lLYe2/YZx84/XTYbbckVp6IxGL77lGnLV8e9mRszYTqmTPh/vtD13aHHcJt778P3/1u6Ar/6lfhsmFD0+Vqa8MbwHnnwZ/+FBK4Vy/o2TOc2eD//i/c75FHYNEi6NePhtL+1PftT+EOA1hZ04XHHoOFC2HuXHj5ZXjjDXjoITjqKJg1K3wIOPxwGDs27EUvItuPrfWocyOo25o7fPwxLF4M69eHy/jxoe2RR+C55+CTT8J4x6pV4f6PPRbajz8eHnyw6eMNGhQeC+DXvw5vLKNGUT18N2zULhQN6ssdd4T3ig0bwpDKYYfBMcfAt7/daLaLiHRYCuqYVFeHIF66NBxIe8mS0NM/44zQ/rWvwZQpTXvsRx4JU6dSXQ3Tb3qdKW8N45F/d2XRIli5MoyJ/+1vYThlr71g993V45aMtWvDl96dOrXuQ+Vn4R4+XDY0hOdrfHtdXfgupro6bLPduoW2xYtDXXl5oU738OG1R4/w+9y54ad7WH7lSigrg112Cc91333hvt26heetq4Nhw8JEgPXr4ZlnwvOkn7+mJgwt7rILrFgRPkCbZb5bKiiA/feHIUPCy/PRR8OytbXhp3voJA0fDgsWhE+91dXhcb/znfDhfVsoqDuahoYw3PLWW2GqSY8eoevc0BCGUyorYdAgluxxOP0PHQlHHskRl+238Ww3ZrDTTmHI5Pe/D7c9/HBYvGfPcOnRI3yZ2atXaK+vzzx9+sVmlnmxffhhWL7x5tK1a1jeHebPDz/z8sIynTqFN4uioswyWwqJhoYQJhBeqHl54bZ0uKxdG8b30y+Uhobw3DvvDH37hve0hQvDG9XateE+9fWw555h1GnpUnjppUxYpF9U48bBgAGh9mefDc9fWxsuNTVw0knQv38YgnryyfCY9fXh+Rsa4JxzwovyhRfCB6b6+sxz19fD//xPWMdTp4YXezps3MPy11wT/r677w4jY7W1Ybn0+koHyC23ZI65nn7s4mKYPDncdsUV4fnTddXXh//xk0+G9iOPhMcfD4/VuXNYduedwygfwNFHw4wZmcd2h/JymD49tB9wQFj/Zpna/+u/Mh8Sd98d3nsv3J4+gOWXvpT54DhwYAi8xtvO6advPPUpJSXhe5vGvvc9uPHGsD4LCzffZi65BH7zm/C/7d9/8/Zf/zrsCDd/fngtbOqGG8Io5ezZoXOzqb/8JUznnT4dPve5zdvvuw++8pXwvz3qqMztc+aEPaS3Re5+mdhR5eWFLsGwYeFV1NjUqSF1XnyR/i/OhMfuhKoqHntsP+a9uobXz/gtr3cq543aUTC/ACpWwMiRnHdeDz74oOlDHX98CAMIG/snnzRtP/PMsMFC6J1selDC884LG3xtbehdbOrHP4arrgq9lr59M72m9M8JE+Dii0OvpLnlb7wxvGDnzctMkWzsjjvCB5EXXwxDQZt64AH48pfD6jq2mRPWP/FECOoXXgh/66YOOiisl5kz4cILN2//yldCUM+YESYTQXhzSV8uvDAE9ezZmVBK/+15eWHddOoEH3wQvoMoLAzLmWVC0Sz0OF97LVxPP3bnzpk6iorCm2L6TS4vL3whnXb++eF7jfSU0+rqpuF25JEhuNOPbZb5egbg1FPD+k2/EZs1/X994xuwbFlYtqgoXBp/AX7BBeF5i4tDW3Fx0/Y//CHzJpWeVbXHHpn1OWlSZp0UFoavf9Lh27t3eCOtrAxfzufnhx5xun3gwPD/cw/LpusbMCC077pr6BOl38TTnYGystBeXh7ehBr3ts1CRwHCev3kk8zjNvem0hbUo+7oKivD1tWnT+g+nHoq/Oc/4fNh2i23sODws/lkxlxW/fcvWFUygNWFpQzuXskRg+fApZcyccZBbPhgGVS8BAWFFBXBHmUrOHqPhXDCCdw6bQi+/BPs3XewwrDF7jq8hoP3qaJhzN789YFu5G1YR/2qNVTVF1JVX8C++8DnDstnnXfm6ol5G3vk6Z7fkUeGnlllZeg1QqpHWOcYzhHj89h77/AinzEjvAgKC8MLZe3aMEumrCyExOOPhxdPuheflxdehH36hK8J3n4780JPv6jKykJvbu3azOnc0u2FheFTR0FBCLZ16zJBlg7D9POkP42kQ0xkW2joI9e4h3Hw+fPho4/CZ7shQ0KAX3klrF4d0nHDhnC59tqQmI8/HqYxbtjQtPv85JOh6zB5MpxyyubP9+KLYRL5rbeGIZpNpT8P3nAD/PSnoUuV7l4VFcHTT4cuzsSJ4fPsqlUh/fr1C12if/87dE3//OcwhpBOyeLikLTXXx+eZ/Lk0H1Od6sKCkJ6X3JJaL/33rAOGnfte/YMYxgQuuAffJDpvpmFpD/55ND+0EOZ7xTSy/frFwYsIYxfrFrVtH3gwEx3/9FHw6Bp4zQfNCjMz0wvX1eXqT0/P7Sn521OmxaWbdz1HTQodG8bGsJHAwi319SELuawYaH7WlcXlu/ePXTH0zUMHBi619XVYTB4U2Vl4eNQVVX4aJN+l0pf+vULg8M1NWGba/y3m4XnKy4O29O6dZu3d+oU/pb04PKm7c2989XXZwabu3YNy69YEcbniosze6OVlITrHeTdc2tBjbu3+WXfffd16eAaGtyrqtwrK91rasJta9a4v/22++uvu1dUuE+f7v7EE+6rV4f2d991v+su99tvd7/pJvff/c796qvdP/kktD/1lPuFF7p/97vuZ53lftpp7ied5L5iRWh/6KHQ9pOfuF9+ufvZZ7sfd5x7fX1onzDBfdQo9513dh861H3gQPcBAzI1f+c77l26uJeUuBcWhuHg3r0z7V/9auNh4nAZMiTTPm7c5u27755pP+igzdsPPDDTPnr05u3jxmXahwzZvP2rX8209+mzefuZZ2bai4o2bz/vvNBWXb15G7hfemloX7Kk+farrgrt8+Y1337DDaH9lVeab7/jjtD+7LPNt993X2ifMqX59mnTQvs99zTfPnNmaL/tNve8PHezpu1z5oT2a69tfvn33w/tEye69+rl3qOHe9euYTvp0sV91arQfvnl7t27h/v07ever1/YvurqQvtll4Vtbqed3IcPdx8xwn3PPTP/m4svDtvmvHm+rYAK30KmtmqM2szGA9cB+cCt7n5Vm72NSJzMMj3ftK5dw8G/t2T48OYHm9MOO6z5weS0444Lly257LJw2ZKbbgqXxhrvSnrPPZlvy9JjMI3985+h59f4pd74GAEPPhh6null3UPPPm3KlEx7+j6NB5OnTt38dHHdu2d+f+aZzCBp+tKvX6b96aebflvpHub7Q+iBT52aee707q/pweaePcNgbWVl6NWnpQeL+/cP35Btas89w8+hQ8P6azx2VV8PhxwS2ocPhz/+senf7h7OugThE9U11zRtc4cRI0L7HnuELy02bU//fWPGhE9jkBmbKiwMvX0In2rKysL6X78+fCpcvz4MYgOMGgWnndb000D6sSB8IvzmN5t+Y1xfn7nfiBHhW8XGtTX+3++wQ/gbGr9e2lCLQx9mlg+8DYwDFgEvAae4+5wtLaOhDxGRT+eznjhgf+Bdd3/P3WuAycCX27JAERHZstYEdRmwsNH1RanbmjCzc8yswswqli1b1lb1iYjkvDY7HrW73+zu5e5eXtp4EqeIiHwmrQnqxUCj6e8MTt0mIiLtoDVB/RIw0syGmVkRcDLwUHbLEhGRtBan57l7nZl9H3iMMD3vdnd/M+uViYgI0Mpjfbj7FGBKlmsREZFmbNcntxUR2R5k5VgfZrYMeH8bF+8LLG/DcrY3Wj8t0zraOq2fliWxjoa4e7NT5rIS1J+FmVVsae8c0fppDa2jrdP6aVls60hDHyIikVNQi4hELsagvjnpAiKn9dMyraOt0/ppWVTrKLoxahERaSrGHrWIiDSioBYRiVw0QW1m483sP2b2rpldmnQ9MTCzHczsKTObY2ZvmtkFqdt7m9k0M3sn9bNX0rUmyczyzewVM3s4dX2Ymb2Q2pbuSR2jJmeZWU8z+6eZzTWzt8zsIG1DGWb2w9Tr6w0zm2RmnWLbhqII6tRZZG4EjgJ2A04xs922vlROqAMucvfdgAOB81Lr5VLgSXcfCTyZup7LLgDeanT9N8C17j4CWAl8K5Gq4nEdMNXdRwFjCOtK2xBgZmXA+UC5u48mHM/oZCLbhqIIanQWmWa5+0fu/nLq9zWEF1gZYd3ckbrbHcDxiRQYATMbDBwD3Jq6bsBY4J+pu+T6+ukBfB64DcDda9x9FdqGGisASsysAOgMfERk21AsQd2qs8jkMjMbCuwNvAD0d/ePUk0fA/2TqisCvwMuAdJnqu0DrHL3utT1XN+WhgHLgD+nhoduNbMuaBsCwN0XAxOBDwgBvRqYRWTbUCxBLVthZl2Be4EL3b2ycVvqNPM5OcfSzI4Flrr7rKRriVgBsA9wk7vvDaxjk2GOHN+GehE+XQwDBgFdgPGJFtWMWIJaZ5HZAjMrJIT039z9vtTNS8xsYKp9ILA0qfoSdgjwJTNbQBguG0sYj+2Z+hgL2pYWAYvc/YXU9X8SglvbUHA4MN/dl7l7LXAfYbuKahuKJah1FplmpMZbbwPecvdrGjU9BJyZ+v1M4MH2ri0G7v4Tdx/s7kMJ28y/3P3rwFPA11J3y9n1A+DuHwMLzWyX1E1fBOagbSjtA+BAM+ucer2l109U21A0eyaa2dGE8cb0WWR+lWxFyTOzQ4FngdfJjMH+lDBO/XdgR8LhZE909xWJFBkJMzsM+JG7H2tmOxF62L2BV4DT3L06wfISZWZ7Eb5sLQLeA75J6KRpGwLM7ArgJMIsq1eAswlj0tFsQ9EEtYiINC+WoQ8REdkCBbWISOQU1CIikVNQi4hETkEtIhI5BbWISOQU1CIikfv/+vQXlBgp6QIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# evenly sampled time at 200ms intervals\n",
    "#t = np.arange(0., 5., 0.2)\n",
    "\n",
    "# red dashes, blue squares and green triangles\n",
    "plt.plot(t_l,'r--', d_l,'b--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8fd16a48-a4fe-4c60-b0c8-c45a065bafd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95406.1875\n",
      "(tensor([2570.], dtype=torch.float64), tensor([2308.6240], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2449.], dtype=torch.float64), tensor([2304.1309], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1895.], dtype=torch.float64), tensor([2479.2815], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2411.], dtype=torch.float64), tensor([2509.1663], grad_fn=<UnbindBackward0>))\n",
      "(tensor([3055.], dtype=torch.float64), tensor([2408.0186], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2078.], dtype=torch.float64), tensor([2662.0854], grad_fn=<UnbindBackward0>))\n",
      "(tensor([831.], dtype=torch.float64), tensor([1153.1610], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1494.], dtype=torch.float64), tensor([1450.1365], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2538.], dtype=torch.float64), tensor([2560.6304], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2443.], dtype=torch.float64), tensor([2536.1909], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2380.], dtype=torch.float64), tensor([2310.3669], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2430.], dtype=torch.float64), tensor([2216.1116], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2278.], dtype=torch.float64), tensor([2000.3635], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1852.], dtype=torch.float64), tensor([1955.5238], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2979.], dtype=torch.float64), tensor([2646.0923], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2576.], dtype=torch.float64), tensor([2744.9106], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1920.], dtype=torch.float64), tensor([2373.5693], grad_fn=<UnbindBackward0>))\n",
      "(tensor([2078.], dtype=torch.float64), tensor([2152.6584], grad_fn=<UnbindBackward0>))\n",
      "(tensor([737.], dtype=torch.float64), tensor([999.6563], grad_fn=<UnbindBackward0>))\n",
      "(tensor([1591.], dtype=torch.float64), tensor([1778.3684], grad_fn=<UnbindBackward0>))\n",
      "0.7309990882672491\n",
      "MAPE for width:  0.13427759419609014\n",
      "MSE for width:  95406.20030055809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "X1_test = torch.tensor(X1_test)\n",
    "X2_test = torch.tensor(X2_test)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "y_predict_1 = net(X1_test.float(), X2_test.float())\n",
    "error = loss_function(y_predict_1, y_test.float())\n",
    "\n",
    "print(error.item())\n",
    "for a in (list(zip(y_test,y_predict_1))):\n",
    "    print(a)\n",
    "    \n",
    "print(r2_score(y_test.detach().numpy()[:,0], y_predict_1.detach().numpy()[:,0]))\n",
    "\n",
    "print('MAPE for width: ', mean_absolute_percentage_error(y_test.detach().numpy()[:,0], y_predict_1.detach().numpy()[:,0]))\n",
    "\n",
    "print('MSE for width: ', mean_squared_error(y_test.detach().numpy()[:,0], y_predict_1.detach().numpy()[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "312ddda9-4c02-477a-84f4-629e32fa4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "\t\"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "\tdef __init__(self, patience, verbose=False, delta=0, save_path='checkpoint.pt'):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\t\tpatience (int): How long to wait after last time validation loss improved.\n",
    "\t\t\t\t\t\t\tDefault: 7\n",
    "\t\t\tverbose (bool): If True, prints a message for each validation loss improvement.\n",
    "\t\t\t\t\t\t\tDefault: False\n",
    "\t\t\tdelta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "\t\t\t\t\t\t\tDefault: 0\n",
    "\t\t\"\"\"\n",
    "\t\tself.patience = patience\n",
    "\t\tself.verbose = verbose\n",
    "\t\tself.counter = 0\n",
    "\t\tself.best_score = None\n",
    "\t\tself.early_stop = False\n",
    "\t\tself.val_loss_min = np.inf\n",
    "\t\tself.delta = delta\n",
    "\t\tself.save_path = save_path\n",
    "\t\tos.makedirs(pathlib.Path(self.save_path).parent, exist_ok=True)\n",
    "\n",
    "\tdef __call__(self, val_loss, model):\n",
    "\n",
    "\t\tscore = -val_loss\n",
    "\n",
    "\t\tif self.best_score is None:\n",
    "\t\t\tself.best_score = score\n",
    "\t\t\tself.save_checkpoint(val_loss, model)\n",
    "\t\telif score < self.best_score - self.delta:\n",
    "\t\t\tself.counter += 1\n",
    "\t\t\tprint(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "\t\t\tif self.counter >= self.patience:\n",
    "\t\t\t\tself.early_stop = True\n",
    "\t\telse:\n",
    "\t\t\tself.best_score = score\n",
    "\t\t\tself.save_checkpoint(val_loss, model)\n",
    "\t\t\tself.counter = 0\n",
    "\n",
    "\tdef save_checkpoint(self, val_loss, model):\n",
    "\t\t\"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "\t\tif self.verbose:\n",
    "\t\t\tprint(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "\t\ttorch.save(model.state_dict(), self.save_path)\n",
    "\t\tself.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32dc3632-32e4-4107-b749-e319a6664ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 15.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  50.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000, 100.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,   8.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  30.0000,  20.0000,   0.0000],\n",
       "        [ 30.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 20.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,  50.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 20.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 30.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.9500,  50.0000,  20.0000,   0.0000],\n",
       "        [ 20.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,  50.0000],\n",
       "        [ 25.0000,   0.9500,  50.0000,  20.0000,   0.0000],\n",
       "        [ 30.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.1400,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.1400,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,   8.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  20.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  30.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,   8.0000,   0.0000],\n",
       "        [ 30.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 30.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,  25.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,  25.0000],\n",
       "        [ 25.0000,   0.4700,  20.0000,  20.0000,   0.0000],\n",
       "        [ 20.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000, 100.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,  50.0000],\n",
       "        [ 25.0000,   0.4700,  30.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.9500,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,  50.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,   8.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  50.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,  50.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 22.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,  50.0000],\n",
       "        [ 25.0000,   0.4700,  20.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 22.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.9500,  50.0000,  20.0000,   0.0000],\n",
       "        [ 22.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 20.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 15.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000, 100.0000],\n",
       "        [ 30.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,  50.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000, 100.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000, 100.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,  25.0000],\n",
       "        [ 25.0000,   0.4700,  50.0000,  20.0000,  25.0000],\n",
       "        [ 25.0000,   0.4700,  30.0000,  20.0000,   0.0000],\n",
       "        [ 20.0000,   0.4700,  50.0000,  20.0000,   0.0000],\n",
       "        [ 30.0000,   0.4700,  50.0000,  20.0000,   0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
